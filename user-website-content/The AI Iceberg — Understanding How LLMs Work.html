<!DOCTYPE html>
<!-- saved from url=(0030)https://iceberg.leonfurze.com/ -->
<html lang="en" data-astro-cid-sckkx6r4="" style="scroll-behavior: smooth;"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="description" content="Explore how Large Language Models work — from training data to ChatGPT — through Leon Furze&#39;s AI Iceberg model."><meta name="theme-color" content="#f0f7f9"><link rel="icon" type="image/svg+xml" href="https://iceberg.leonfurze.com/favicon.svg"><link rel="preconnect" href="https://rsms.me/"><link rel="stylesheet" href="./The AI Iceberg — Understanding How LLMs Work_files/inter.css"><title>The AI Iceberg — Understanding How LLMs Work</title><link rel="stylesheet" href="./The AI Iceberg — Understanding How LLMs Work_files/index.VK2lwjut.css"></head> <body data-astro-cid-sckkx6r4=""> <a href="https://iceberg.leonfurze.com/#main-content" class="skip-link" data-astro-cid-sckkx6r4="">Skip to main content</a>  <canvas id="particle-canvas" aria-hidden="true" data-astro-cid-lmxfb4hx="" width="1920" height="838" style="width: 1280px; height: 559px;"></canvas>  <script type="module">const s=document.getElementById("particle-canvas"),e=s.getContext("2d");if(e){let p=function(){return window.matchMedia("(prefers-reduced-motion: reduce)").matches},h=function(){return window.innerWidth<768?S:R},u=function(){const t=.1+Math.random()*.2;return{x:Math.random()*a,y:Math.random()*o,vx:(Math.random()-.5)*x*2,vy:(Math.random()-.5)*x*2,radius:g+Math.random()*(O-g),color:M[Math.floor(Math.random()*M.length)],opacity:t,baseOpacity:t}},v=function(){const t=h();n=[];for(let i=0;i<t;i++)n.push(u())},m=function(){const t=Math.min(window.devicePixelRatio||1,2);a=window.innerWidth,o=window.innerHeight,s.width=a*t,s.height=o*t,s.style.width=a+"px",s.style.height=o+"px",e.setTransform(t,0,0,t,0,0)},y=function(){for(let t=0;t<n.length;t++)for(let i=t+1;i<n.length;i++){const A=n[t].x-n[i].x,E=n[t].y-n[i].y,T=A*A+E*E,b=f*f;if(T<b){const D=(1-Math.sqrt(T)/f)*.08;e.beginPath(),e.moveTo(n[t].x,n[t].y),e.lineTo(n[i].x,n[i].y),e.strokeStyle=`rgba(56, 189, 248, ${D})`,e.lineWidth=.5,e.stroke()}}},w=function(t){e.beginPath(),e.arc(t.x,t.y,t.radius*3,0,Math.PI*2),e.fillStyle=t.color+t.opacity*.3+")",e.fill(),e.beginPath(),e.arc(t.x,t.y,t.radius,0,Math.PI*2),e.fillStyle=t.color+t.opacity+")",e.fill()},I=function(){for(const t of n)t.x+=t.vx,t.y+=t.vy,t.x<-10&&(t.x=a+10),t.x>a+10&&(t.x=-10),t.y<-10&&(t.y=o+10),t.y>o+10&&(t.y=-10),t.opacity=t.baseOpacity+Math.sin(Date.now()*.001+t.x*.01)*.05},l=function(){e.clearRect(0,0,a,o);const t=P*_;e.save(),e.translate(0,-t%o),y();for(const i of n)w(i);e.restore(),c||I(),r=requestAnimationFrame(l)},d=function(){e.clearRect(0,0,a,o),y();for(const t of n)w(t)},L=function(){c=p(),m(),v(),c?d():l()};const R=50,S=25,f=140,g=1,O=2.5,x=.15,_=.08,M=["rgba(0, 212, 255,","rgba(14, 165, 233,","rgba(56, 189, 248,","rgba(125, 211, 252,"];let n=[],r=null,P=0,a=0,o=0,c=!1;window.addEventListener("scroll",()=>{P=window.scrollY},{passive:!0});let C;window.addEventListener("resize",()=>{clearTimeout(C),C=setTimeout(()=>{m();const t=n.length,i=h();if(i<t)n.length=i;else for(;n.length<i;)n.push(u());c&&d()},200)}),window.matchMedia("(prefers-reduced-motion: reduce)").addEventListener("change",t=>{c=t.matches,c?(r!==null&&(cancelAnimationFrame(r),r=null),d()):l()}),document.addEventListener("astro:before-swap",()=>{r!==null&&(cancelAnimationFrame(r),r=null)}),L()}</script>  <div class="progress-bar" id="progress-bar" aria-hidden="true" data-astro-cid-j7pv25f6="" style="width: 3.123%;"></div>    <section class="hero" id="hero" aria-label="Introduction" data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate3d(0px, -49.7339px, 0px); opacity: 0.0053;"> <p class="label" id="hero-label" data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 0px); opacity: 1;">Leon Furze's AI Iceberg</p> <h1 id="hero-title" data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 0px); opacity: 1;">Understanding How<br data-astro-cid-j7pv25f6="">AI Really Works</h1> <p class="subtitle" id="hero-subtitle" data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 0px); opacity: 1;">
Scroll down to dive beneath the surface of AI, exploring the hidden
      layers of large language models — from the applications you see to the
      vast ocean of training data you don't.
</p> <div class="scroll-cue" id="scroll-cue" data-astro-cid-j7pv25f6="" style="opacity: 1;"> <span data-astro-cid-j7pv25f6="">Scroll to explore</span> <div class="arrow" aria-hidden="true" data-astro-cid-j7pv25f6=""></div> </div> </section>    <section id="main-content" aria-label="The AI Iceberg overview" tabindex="-1" data-astro-cid-j7pv25f6=""> <div class="chapter-divider" id="ch-iceberg" data-astro-cid-j7pv25f6=""> <span class="chapter-number" data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 0px); opacity: 1;">The Big Picture</span> <h2 id="ch-iceberg-title" data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 0px); opacity: 1;">The AI Iceberg</h2> <p id="ch-iceberg-desc" data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 0px); opacity: 1;">
Most people interact with AI through polished applications like ChatGPT,
        Claude, or Gemini. But like an iceberg, what you see is only a tiny fraction of what's really
        there. The vast majority — the training data, the model architecture, the
        hidden processes — lies beneath the surface.
</p> </div> <!-- Sticky iceberg with scrolling text annotations --> <div class="scroll-container" id="iceberg-scroll" data-astro-cid-j7pv25f6=""> <div class="sticky-graphic" id="iceberg-sticky" data-astro-cid-j7pv25f6=""> <div class="iceberg-wrapper" id="iceberg-wrapper" data-astro-cid-w3a3lohl=""> <img src="./The AI Iceberg — Understanding How LLMs Work_files/iceberg.png" alt="The AI Iceberg: A snowman representing applications sits atop an iceberg. Above the waterline is the LLM layer. Below, the massive dataset is hidden underwater, with a shark representing threats like bias and misinformation." class="iceberg-image" loading="eager" draggable="false" data-astro-cid-w3a3lohl=""> <!-- LAYER 3: Applications label --> <div id="label-applications" class="iceberg-label apps-label" aria-label="Layer 3: Applications" data-astro-cid-w3a3lohl="" style="opacity: 1;"> <div class="label-content" data-astro-cid-w3a3lohl=""> <span class="label-title" data-astro-cid-w3a3lohl="">Applications</span> <span class="label-sub" data-astro-cid-w3a3lohl="">ChatGPT, Claude, Gemini &amp; more</span> <span class="label-detail" data-astro-cid-w3a3lohl="">RLHF + System Messages</span> </div> <div class="connector connector-right" aria-hidden="true" data-astro-cid-w3a3lohl=""></div> </div> <!-- LAYER 2: LLM label --> <div id="label-llm" class="iceberg-label llm-label" aria-label="Layer 2: The LLM" data-astro-cid-w3a3lohl="" style="opacity: 0;"> <div class="connector connector-left" aria-hidden="true" data-astro-cid-w3a3lohl=""></div> <div class="label-content" data-astro-cid-w3a3lohl=""> <span class="label-title" data-astro-cid-w3a3lohl="">The LLM</span> <span class="label-sub" data-astro-cid-w3a3lohl="">Tokenization, Weighting,</span> <span class="label-sub" data-astro-cid-w3a3lohl="">Attention &amp; Transformers</span> </div> </div> <!-- LAYER 1: Dataset label --> <div id="label-dataset" class="iceberg-label dataset-label" aria-label="Layer 1: The Dataset" data-astro-cid-w3a3lohl="" style="opacity: 0;"> <div class="label-content" data-astro-cid-w3a3lohl=""> <span class="label-title" data-astro-cid-w3a3lohl="">The Dataset</span> <span class="label-sub" data-astro-cid-w3a3lohl="">~13 trillion tokens of training data</span> <span class="label-detail" data-astro-cid-w3a3lohl="">Common Crawl, Wikipedia, GitHub, books, web pages</span> </div> </div> <!-- EXTENDED: Ocean + Sharks — combined into one label near the shark --> <div id="label-ocean" class="iceberg-label ocean-label" aria-label="The Ocean and its threats" data-astro-cid-w3a3lohl="" style="opacity: 0;"> <div class="label-content ocean-content" data-astro-cid-w3a3lohl=""> <span class="label-title ocean-title" data-astro-cid-w3a3lohl="">The Ocean &amp; The Sharks</span> <span class="label-sub ocean-sub" data-astro-cid-w3a3lohl="">The internet — source of the training data</span> <span class="label-detail ocean-threats" data-astro-cid-w3a3lohl="">Bias, misinformation, and explicit content</span> </div> </div> <!-- shark-labels kept for GSAP compatibility (fades in with ocean) --> <div id="shark-labels" style="display: none; opacity: 0;" aria-hidden="true" data-astro-cid-w3a3lohl=""></div> </div>  </div> <div class="scroll-text" data-astro-cid-j7pv25f6=""> <div class="step" data-step="snowman" id="step-snowman" data-astro-cid-j7pv25f6=""> <h3 data-astro-cid-j7pv25f6="">Layer 3: The Application</h3> <p data-astro-cid-j7pv25f6="">
Picture a carefully sculpted snowman sitting on top of the iceberg.
            This represents an application like ChatGPT, Claude, or Gemini —
            built on top of a general LLM and fine-tuned specifically for
            conversational tasks.
</p> <p data-astro-cid-j7pv25f6="">
The chatbot layer includes <strong data-astro-cid-j7pv25f6="">system messages</strong> (rules
            governing every interaction) and <strong data-astro-cid-j7pv25f6="">RLHF</strong>
(reinforcement learning from human feedback), where human reviewers
            judge outputs as helpful, harmful, correct, or incorrect — shaping
            how the model responds.
</p> </div> <div class="step" data-step="llm" id="step-llm" data-astro-cid-j7pv25f6=""> <h3 data-astro-cid-j7pv25f6="">Layer 2: The LLM</h3> <p data-astro-cid-j7pv25f6="">
The visible iceberg above the waterline is the Large Language Model
            itself — the result of the training process fuelled by the vast
            dataset beneath. This is where three key technical processes happen.
</p> <p data-astro-cid-j7pv25f6=""> <strong data-astro-cid-j7pv25f6="">Tokenization</strong> breaks text into machine-readable
            pieces. <strong data-astro-cid-j7pv25f6="">Weighting</strong> assigns probability values to
            connections between tokens. And the
<strong data-astro-cid-j7pv25f6="">transformer architecture</strong> with its
<strong data-astro-cid-j7pv25f6="">attention mechanism</strong> — introduced in 2017 by Google
            researchers — allows the model to consider relationships across
            entire passages of text.
</p> <p data-astro-cid-j7pv25f6="">
LLMs are often called "black boxes" because their internal
            connections are so massively complex that no human or team of humans
            could possibly unravel everything going on inside.
</p> </div> <div class="step" data-step="dataset" id="step-dataset" data-astro-cid-j7pv25f6=""> <h3 data-astro-cid-j7pv25f6="">Layer 1: The Dataset</h3> <p data-astro-cid-j7pv25f6="">
The bulk of the iceberg — hidden underwater — represents the vast
            dataset on which the LLM is trained. GPT-4 trained on roughly
<strong data-astro-cid-j7pv25f6="">13 trillion tokens</strong> — about 1,600 times the
            population of Earth.
</p> <p data-astro-cid-j7pv25f6="">
Known data sources include Common Crawl, The Pile, Wikipedia,
            GitHub, and social media. Much of the data remains proprietary.
            This layer carries plenty of side effects, including the kind of
            bias and discrimination central to AI ethics discussions.
</p> </div> <div class="step" data-step="ocean" id="step-ocean" data-astro-cid-j7pv25f6=""> <h3 data-astro-cid-j7pv25f6="">The Ocean &amp; The Sharks</h3> <p data-astro-cid-j7pv25f6="">
The ocean surrounding the iceberg represents the internet at large —
            the vast environment from which the dataset is sourced.
</p> <p data-astro-cid-j7pv25f6="">
And the sharks? They symbolize threats lurking in the data:
<strong data-astro-cid-j7pv25f6="">misinformation</strong>, <strong data-astro-cid-j7pv25f6="">bias</strong>,
<strong data-astro-cid-j7pv25f6="">toxic content</strong>, and <strong data-astro-cid-j7pv25f6="">data privacy
            issues</strong> that can influence the dataset and, subsequently,
            the behaviour of the LLM.
</p> <blockquote class="pull-quote" id="bender-quote" data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 15px); opacity: 0;"> <p data-astro-cid-j7pv25f6="">
“A language model is a stochastic parrot — it
              haphazardly stitches together sequences of linguistic forms
              from its training data, without any reference to meaning.”
</p> <cite data-astro-cid-j7pv25f6="">— Emily Bender et al., “On the Dangers of Stochastic Parrots” (2021)</cite> </blockquote> </div> </div> </div> </section>    <section aria-label="How LLMs work — deep dive" data-astro-cid-j7pv25f6=""> <div class="chapter-divider" id="ch-beneath" data-astro-cid-j7pv25f6=""> <span class="chapter-number" data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 15px); opacity: 0;">Beneath the Surface</span> <h2 data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 20px); opacity: 0;">How It Actually Works</h2> <p data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 15px); opacity: 0;">
Let's open the black box. The following sections explore the key
        processes that make large language models tick — from breaking text
        into tokens to predicting the next word.
</p> </div> <!-- NEXT-TOKEN PREDICTION intro --> <div class="full-section" id="next-token-section" data-astro-cid-j7pv25f6=""> <span class="label" data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 10px); opacity: 0;">The Core Insight</span> <h2 id="next-token-title" data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 20px); opacity: 0;">The World's Most Sophisticated Autocomplete</h2> <p id="next-token-p1" data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 20px); opacity: 0;">
Here's the single most important thing to understand about how LLMs work:
        they build text <strong data-astro-cid-j7pv25f6="">one word at a time</strong>, each time predicting
        the most likely next token based on everything that came before.
</p> <p id="next-token-p2" data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 20px); opacity: 0;">
Think of the autocomplete on your phone. You type "I'm on my" and it
        suggests "way." An LLM does the same thing — but with vastly more
        context, vastly more data, and vastly more sophistication. It doesn't
        "understand" your message. It predicts what comes next.
</p> <p id="next-token-p3" style="color: var(--text-muted); font-style: italic; font-size: 0.95rem; translate: none; rotate: none; scale: none; transform: translate(0px, 20px); opacity: 0;" data-astro-cid-j7pv25f6="">
As AI researcher Gary Marcus puts it, large language models are
        “glorified autocomplete” — impressive in their output,
        but fundamentally just predicting the next word.
</p> </div> <!-- TOKENIZATION --> <div class="chapter-divider" id="ch-tokens" data-astro-cid-j7pv25f6=""> <span class="chapter-number" data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 15px); opacity: 0;">Process 1</span> <h2 data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 20px); opacity: 0;">Tokenization</h2> <p data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 15px); opacity: 0;">
Before an LLM can process language, text must be broken into small
        pieces called tokens — like Scrabble tiles the model can work with.
</p> </div> <p class="viz-instruction" data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 10px); opacity: 0;">Scroll to see how text is broken into tokens</p> <section class="token-viz" id="token-viz-section" aria-label="Tokenization visualization" data-astro-cid-trebv57l=""> <div class="token-viz__inner" data-astro-cid-trebv57l=""> <div class="token-viz__text-col" data-token-text="" data-astro-cid-trebv57l=""> <p class="token-viz__label" data-astro-cid-trebv57l="">Original text</p> <p class="token-viz__sentence" id="token-original-sentence" data-astro-cid-trebv57l="">The animal didn't cross the street because it was too tired</p> <div class="token-viz__arrow" data-token-arrow="" aria-hidden="true" data-astro-cid-trebv57l="" style="opacity: 1; transform: none;"> <svg width="24" height="48" viewBox="0 0 24 48" data-astro-cid-trebv57l=""> <path d="M12 0 L12 40 M4 32 L12 44 L20 32" stroke="currentColor" stroke-width="2" fill="none" stroke-linecap="round" stroke-linejoin="round" data-astro-cid-trebv57l=""></path> </svg> <span class="token-viz__arrow-label" data-astro-cid-trebv57l="">Tokenizer (BPE)</span> </div> <p class="token-viz__label" data-astro-cid-trebv57l="">Tokens</p> <div class="token-viz__grid" id="token-grid" role="list" aria-label="Tokenized output" data-astro-cid-trebv57l=""> <div class="token-viz__token token-viz__token--word" data-token-index="0" data-token-type="word" role="listitem" aria-label="Token: &quot;The&quot;, ID: 464, type: word" data-astro-cid-trebv57l="" style="opacity: 1; transform: none;"> <span class="token-viz__token-text" data-astro-cid-trebv57l="">The</span> <span class="token-viz__token-id" data-token-id="" data-astro-cid-trebv57l="" style="opacity: 1; transform: none;">464</span> </div><div class="token-viz__token token-viz__token--word" data-token-index="1" data-token-type="word" role="listitem" aria-label="Token: &quot;animal&quot;, ID: 5765, type: word" data-astro-cid-trebv57l="" style="opacity: 1; transform: none;"> <span class="token-viz__token-text" data-astro-cid-trebv57l=""> animal</span> <span class="token-viz__token-id" data-token-id="" data-astro-cid-trebv57l="" style="opacity: 1; transform: none;">5765</span> </div><div class="token-viz__token token-viz__token--subword" data-token-index="2" data-token-type="subword" role="listitem" aria-label="Token: &quot;didn&quot;, ID: 1422, type: subword" data-astro-cid-trebv57l="" style="opacity: 1; transform: none;"> <span class="token-viz__token-text" data-astro-cid-trebv57l=""> didn</span> <span class="token-viz__token-id" data-token-id="" data-astro-cid-trebv57l="" style="opacity: 1; transform: none;">1422</span> </div><div class="token-viz__token token-viz__token--subword" data-token-index="3" data-token-type="subword" role="listitem" aria-label="Token: &quot;&#39;t&quot;, ID: 956, type: subword" data-astro-cid-trebv57l="" style="opacity: 1; transform: none;"> <span class="token-viz__token-text" data-astro-cid-trebv57l="">'t</span> <span class="token-viz__token-id" data-token-id="" data-astro-cid-trebv57l="" style="opacity: 1; transform: none;">956</span> </div><div class="token-viz__token token-viz__token--word" data-token-index="4" data-token-type="word" role="listitem" aria-label="Token: &quot;cross&quot;, ID: 3108, type: word" data-astro-cid-trebv57l="" style="opacity: 1; transform: none;"> <span class="token-viz__token-text" data-astro-cid-trebv57l=""> cross</span> <span class="token-viz__token-id" data-token-id="" data-astro-cid-trebv57l="" style="opacity: 1; transform: none;">3108</span> </div><div class="token-viz__token token-viz__token--word" data-token-index="5" data-token-type="word" role="listitem" aria-label="Token: &quot;the&quot;, ID: 279, type: word" data-astro-cid-trebv57l="" style="opacity: 1; transform: none;"> <span class="token-viz__token-text" data-astro-cid-trebv57l=""> the</span> <span class="token-viz__token-id" data-token-id="" data-astro-cid-trebv57l="" style="opacity: 1; transform: none;">279</span> </div><div class="token-viz__token token-viz__token--word" data-token-index="6" data-token-type="word" role="listitem" aria-label="Token: &quot;street&quot;, ID: 8080, type: word" data-astro-cid-trebv57l="" style="opacity: 1; transform: none;"> <span class="token-viz__token-text" data-astro-cid-trebv57l=""> street</span> <span class="token-viz__token-id" data-token-id="" data-astro-cid-trebv57l="" style="opacity: 1; transform: none;">8080</span> </div><div class="token-viz__token token-viz__token--word" data-token-index="7" data-token-type="word" role="listitem" aria-label="Token: &quot;because&quot;, ID: 1606, type: word" data-astro-cid-trebv57l="" style="opacity: 1; transform: none;"> <span class="token-viz__token-text" data-astro-cid-trebv57l=""> because</span> <span class="token-viz__token-id" data-token-id="" data-astro-cid-trebv57l="" style="opacity: 1; transform: none;">1606</span> </div><div class="token-viz__token token-viz__token--word" data-token-index="8" data-token-type="word" role="listitem" aria-label="Token: &quot;it&quot;, ID: 433, type: word" data-astro-cid-trebv57l="" style="opacity: 1; transform: none;"> <span class="token-viz__token-text" data-astro-cid-trebv57l=""> it</span> <span class="token-viz__token-id" data-token-id="" data-astro-cid-trebv57l="" style="opacity: 1; transform: none;">433</span> </div><div class="token-viz__token token-viz__token--word" data-token-index="9" data-token-type="word" role="listitem" aria-label="Token: &quot;was&quot;, ID: 574, type: word" data-astro-cid-trebv57l="" style="opacity: 1; transform: none;"> <span class="token-viz__token-text" data-astro-cid-trebv57l=""> was</span> <span class="token-viz__token-id" data-token-id="" data-astro-cid-trebv57l="" style="opacity: 1; transform: none;">574</span> </div><div class="token-viz__token token-viz__token--word" data-token-index="10" data-token-type="word" role="listitem" aria-label="Token: &quot;too&quot;, ID: 2288, type: word" data-astro-cid-trebv57l="" style="opacity: 1; transform: none;"> <span class="token-viz__token-text" data-astro-cid-trebv57l=""> too</span> <span class="token-viz__token-id" data-token-id="" data-astro-cid-trebv57l="" style="opacity: 1; transform: none;">2288</span> </div><div class="token-viz__token token-viz__token--word" data-token-index="11" data-token-type="word" role="listitem" aria-label="Token: &quot;tired&quot;, ID: 12544, type: word" data-astro-cid-trebv57l="" style="opacity: 1; transform: none;"> <span class="token-viz__token-text" data-astro-cid-trebv57l=""> tired</span> <span class="token-viz__token-id" data-token-id="" data-astro-cid-trebv57l="" style="opacity: 1; transform: none;">12544</span> </div> </div> <div class="token-viz__legend" data-token-legend="" data-astro-cid-trebv57l="" style="opacity: 1; transform: none;"> <div class="token-viz__legend-item" data-astro-cid-trebv57l=""> <span class="token-viz__legend-swatch token-viz__legend-swatch--word" data-astro-cid-trebv57l=""></span> <span data-astro-cid-trebv57l="">Full word</span> </div> <div class="token-viz__legend-item" data-astro-cid-trebv57l=""> <span class="token-viz__legend-swatch token-viz__legend-swatch--subword" data-astro-cid-trebv57l=""></span> <span data-astro-cid-trebv57l="">Subword piece</span> </div> </div> </div> <div class="token-viz__explain-col" data-token-explain="" data-astro-cid-trebv57l="" style="opacity: 1; transform: none;"> <div class="token-viz__explainer" data-astro-cid-trebv57l=""> <h3 class="token-viz__explainer-title" data-astro-cid-trebv57l="">Tokens: The Scrabble Tiles of AI</h3> <p data-astro-cid-trebv57l="">
Before an LLM can process text, it must break it into <strong data-astro-cid-trebv57l="">tokens</strong> —
          small pieces it can work with, like Scrabble tiles.
</p> <p data-astro-cid-trebv57l="">
Tokens are not always whole words. The tokenizer uses <strong data-astro-cid-trebv57l="">Byte-Pair Encoding (BPE)</strong>
to split rare or compound words into smaller, more common pieces. Notice how
<em data-astro-cid-trebv57l="">“didn’t”</em> becomes two tokens: <code data-astro-cid-trebv57l="">didn</code> and <code data-astro-cid-trebv57l="">’t</code>.
</p> <p data-astro-cid-trebv57l="">
Each token is then mapped to a <strong data-astro-cid-trebv57l="">numerical ID</strong> — the only thing the model
          actually sees. GPT-4’s vocabulary contains roughly 100,000 possible tokens.
</p> <p class="token-viz__aside" data-astro-cid-trebv57l="">
As Andrej Karpathy explains, “a lot of weird behaviors and problems of LLMs
          actually trace back to tokenization.”
</p> </div> </div> </div> </section>  <script type="module">function s(){const t=window.gsap,l=window.ScrollTrigger;if(!t||!l){document.querySelectorAll(".token-viz__token, .token-viz__arrow, .token-viz__legend, .token-viz__explain-col, .token-viz__token-id").forEach(d=>{d.style.opacity="1",d.style.transform="none"});return}const u=window.matchMedia("(prefers-reduced-motion: reduce)").matches,e=document.getElementById("token-viz-section");if(!e)return;const n=e.querySelectorAll(".token-viz__token"),r=e.querySelectorAll("[data-token-id]"),a=e.querySelector("[data-token-arrow]"),i=e.querySelector("[data-token-legend]"),o=e.querySelector("[data-token-explain]"),c=t.timeline({scrollTrigger:{trigger:e,start:"top 75%",end:"bottom 25%",toggleActions:"play none none reverse"}});u?c.to(a,{opacity:1,duration:.3}).to(n,{opacity:1,y:0,scale:1,duration:.3,stagger:0},"<").to(r,{opacity:.35,duration:.3},"<").to(i,{opacity:1,duration:.3},"<").to(o,{opacity:1,duration:.3},"<"):(c.to(a,{opacity:1,duration:.4,ease:"power2.out"}).to(n,{opacity:1,y:0,scale:1,duration:.35,stagger:.06,ease:"back.out(1.4)"},"-=0.1").to(r,{opacity:.35,duration:.3,stagger:.04,ease:"power2.out"},"-=0.3").to(i,{opacity:1,duration:.4,ease:"power2.out"},"-=0.2").to(o,{opacity:1,x:0,duration:.5,ease:"power2.out"},"-=0.4"),t.set(o,{x:20}))}document.readyState==="loading"?document.addEventListener("DOMContentLoaded",s):s();</script> <!-- EMBEDDINGS --> <div class="chapter-divider" id="ch-embeddings" data-astro-cid-j7pv25f6=""> <span class="chapter-number" data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 15px); opacity: 0;">Process 2</span> <h2 data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 20px); opacity: 0;">Embeddings</h2> <p data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 15px); opacity: 0;">
Each token becomes a numerical vector — essentially GPS coordinates in
        "meaning space," where similar concepts naturally cluster together.
        These positions are learned during training, not hand-coded.
</p> </div> <p class="viz-instruction" data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 10px); opacity: 0;">Scroll to explore meaning space</p> <section class="embed-section" id="embedding-viz-section" aria-label="Word embeddings 3D visualization" data-astro-cid-cdl4ct7r=""> <div class="embed-container" data-astro-cid-cdl4ct7r=""> <div class="embed-text-content" data-embed="text" data-astro-cid-cdl4ct7r=""> <h2 class="embed-heading" data-astro-cid-cdl4ct7r="">Meaning Space</h2> <p class="embed-desc" data-astro-cid-cdl4ct7r="">
Every word becomes a point in this space. As the model trains on billions
        of sentences, it learns to place words that appear in similar contexts near
        each other. The result is a rich geometric landscape where relationships
        between words are captured as <strong data-astro-cid-cdl4ct7r="">directions</strong> and
<strong data-astro-cid-cdl4ct7r="">distances</strong>.
</p> </div> <div class="embed-canvas-wrap" data-embed="canvas-wrap" data-astro-cid-cdl4ct7r=""> <canvas id="embedding-canvas" role="img" aria-label="3D rotating visualization of word embedding space showing clusters of similar words: places like Paris, Tokyo, London; animals like dog, cat, puppy; emotions like happy, sad, love; and science terms like atom, cell, DNA. The direction from France to Paris is the same as from Japan to Tokyo, encoding the capital-of relationship." aria-describedby="embed-analogy-desc" data-astro-cid-cdl4ct7r=""></canvas> </div> <div class="embed-legend" data-embed="legend" data-astro-cid-cdl4ct7r=""> <span class="embed-legend-item" data-astro-cid-cdl4ct7r=""> <span class="embed-legend-dot" style="background: #38bdf8" data-astro-cid-cdl4ct7r=""></span>Places
</span> <span class="embed-legend-item" data-astro-cid-cdl4ct7r=""> <span class="embed-legend-dot" style="background: #34d399" data-astro-cid-cdl4ct7r=""></span>Animals
</span> <span class="embed-legend-item" data-astro-cid-cdl4ct7r=""> <span class="embed-legend-dot" style="background: #fb7185" data-astro-cid-cdl4ct7r=""></span>Emotions
</span> <span class="embed-legend-item" data-astro-cid-cdl4ct7r=""> <span class="embed-legend-dot" style="background: #a78bfa" data-astro-cid-cdl4ct7r=""></span>Science
</span> </div> <div class="embed-analogy-wrap" id="embed-analogy-desc" data-embed="analogy" data-astro-cid-cdl4ct7r=""> <p class="embed-formula" data-astro-cid-cdl4ct7r="">Paris − France + Japan ≈ Tokyo</p> <p class="embed-analogy-explain" data-astro-cid-cdl4ct7r="">
The direction from France to Paris encodes the concept <em data-astro-cid-cdl4ct7r="">"capital of."</em>
Apply that same direction starting from Japan and you land near Tokyo. The model
        discovers these geometric relationships entirely on its own, by predicting which
        words appear in similar contexts across billions of sentences.
</p> <p class="embed-cite" data-astro-cid-cdl4ct7r="">
First demonstrated by Mikolov et al. (2013) with Word2Vec. Modern LLMs use
<strong data-astro-cid-cdl4ct7r="">contextual embeddings</strong> where a word's position shifts depending on
        the sentence around it — "bank" moves toward finance or rivers depending on context.
</p> </div> </div> </section>  <script type="module" src="./The AI Iceberg — Understanding How LLMs Work_files/EmbeddingViz.astro_astro_type_script_index_0_lang.D3KPmZ69.js.download"></script> <!-- ATTENTION --> <div class="chapter-divider" id="ch-attention" data-astro-cid-j7pv25f6=""> <span class="chapter-number" data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 15px); opacity: 0;">Process 3</span> <h2 data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 20px); opacity: 0;">Attention</h2> <p data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 15px); opacity: 0;">
The breakthrough that made modern AI possible. The attention mechanism
        lets each word look at every other word to understand context — resolving
        ambiguity in ways previous architectures couldn't.
</p> </div> <p class="viz-instruction" data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 10px); opacity: 0;">Scroll to see attention in action</p> <section class="attention-viz" id="attention-viz-section" aria-label="Attention mechanism visualization" data-astro-cid-ycjemex4=""> <div class="attention-viz__inner" data-astro-cid-ycjemex4=""> <!-- Part 1: Pronoun resolution --> <div class="attention-viz__block" id="attention-pronoun-block" data-attention-block="pronoun" data-astro-cid-ycjemex4=""> <h3 class="attention-viz__heading" data-astro-cid-ycjemex4="">Self-Attention: Resolving “it”</h3> <p class="attention-viz__desc" data-astro-cid-ycjemex4="">
When the model encounters the word <strong data-astro-cid-ycjemex4="">“it”</strong>, attention lets it look at
        every other word and decide which ones are relevant. The thicker the line, the more attention
        “it” pays to that word.
</p> <div class="attention-viz__sentence-wrap" data-astro-cid-ycjemex4=""> <svg class="attention-viz__arcs" id="attention-arcs-svg" viewBox="0 0 880 160" preserveAspectRatio="xMidYMid meet" aria-hidden="true" data-astro-cid-ycjemex4=""> <!-- Arcs are drawn by the script --> </svg> <div class="attention-viz__words" id="attention-words" role="list" aria-label="Sentence words with attention weights" data-astro-cid-ycjemex4=""> <span class="attention-viz__word  " data-word-index="0" role="listitem" aria-label="The" data-astro-cid-ycjemex4=""> The </span><span class="attention-viz__word  attention-viz__word--target" data-word-index="1" role="listitem" aria-label="animal (strongest attention target)" data-astro-cid-ycjemex4=""> animal </span><span class="attention-viz__word  " data-word-index="2" role="listitem" aria-label="didn&#39;t" data-astro-cid-ycjemex4=""> didn't </span><span class="attention-viz__word  " data-word-index="3" role="listitem" aria-label="cross" data-astro-cid-ycjemex4=""> cross </span><span class="attention-viz__word  " data-word-index="4" role="listitem" aria-label="the" data-astro-cid-ycjemex4=""> the </span><span class="attention-viz__word  " data-word-index="5" role="listitem" aria-label="street" data-astro-cid-ycjemex4=""> street </span><span class="attention-viz__word  " data-word-index="6" role="listitem" aria-label="because" data-astro-cid-ycjemex4=""> because </span><span class="attention-viz__word attention-viz__word--source " data-word-index="7" role="listitem" aria-label="it (source of attention query)" data-astro-cid-ycjemex4=""> it </span><span class="attention-viz__word  " data-word-index="8" role="listitem" aria-label="was" data-astro-cid-ycjemex4=""> was </span><span class="attention-viz__word  " data-word-index="9" role="listitem" aria-label="too" data-astro-cid-ycjemex4=""> too </span><span class="attention-viz__word  " data-word-index="10" role="listitem" aria-label="tired" data-astro-cid-ycjemex4=""> tired </span> </div> </div> </div> <!-- QKV explanation --> <div class="attention-viz__qkv" id="attention-qkv" data-attention-qkv="" data-astro-cid-ycjemex4=""> <h4 class="attention-viz__qkv-title" data-astro-cid-ycjemex4="">Query, Key, Value — A Library Analogy</h4> <div class="attention-viz__qkv-cards" data-astro-cid-ycjemex4=""> <div class="attention-viz__qkv-card" data-qkv="query" data-astro-cid-ycjemex4=""> <div class="attention-viz__qkv-icon" data-astro-cid-ycjemex4="">Q</div> <div class="attention-viz__qkv-label" data-astro-cid-ycjemex4="">Query</div> <p data-astro-cid-ycjemex4="">“What am I looking for?”<br data-astro-cid-ycjemex4="">The word “it” asks: <em data-astro-cid-ycjemex4="">“What noun do I refer to?”</em></p> </div> <div class="attention-viz__qkv-card" data-qkv="key" data-astro-cid-ycjemex4=""> <div class="attention-viz__qkv-icon" data-astro-cid-ycjemex4="">K</div> <div class="attention-viz__qkv-label" data-astro-cid-ycjemex4="">Key</div> <p data-astro-cid-ycjemex4="">“What do I contain?”<br data-astro-cid-ycjemex4="">Each word advertises its identity, like a library catalogue entry.</p> </div> <div class="attention-viz__qkv-card" data-qkv="value" data-astro-cid-ycjemex4=""> <div class="attention-viz__qkv-icon" data-astro-cid-ycjemex4="">V</div> <div class="attention-viz__qkv-label" data-astro-cid-ycjemex4="">Value</div> <p data-astro-cid-ycjemex4="">“Here’s my actual information.”<br data-astro-cid-ycjemex4="">The content retrieved once Query matches a Key.</p> </div> </div> </div> <!-- Part 2: Mole disambiguation --> <div class="attention-viz__block" id="attention-mole-block" data-attention-block="mole" data-astro-cid-ycjemex4=""> <h3 class="attention-viz__heading" data-astro-cid-ycjemex4="">Contextual Attention: The “Mole” Problem</h3> <p class="attention-viz__desc" data-astro-cid-ycjemex4="">
The word <strong data-astro-cid-ycjemex4="">“mole”</strong> means completely different things depending on context.
        Attention lets the model figure out which meaning is intended by attending to surrounding words.
</p> <div class="attention-viz__mole-grid" data-astro-cid-ycjemex4=""> <div class="attention-viz__mole-card" id="mole-animal" data-mole-card="animal" data-astro-cid-ycjemex4=""> <span class="attention-viz__mole-label" style="color: #34d399" data-astro-cid-ycjemex4="">Animal</span> <div class="attention-viz__mole-sentence-wrap" data-astro-cid-ycjemex4=""> <svg class="attention-viz__mole-arcs" data-mole-arcs="mole-animal" viewBox="0 0 560 100" preserveAspectRatio="xMidYMid meet" aria-hidden="true" data-astro-cid-ycjemex4=""> <!-- Arcs drawn by script --> </svg> <div class="attention-viz__mole-words" data-mole-words="mole-animal" data-astro-cid-ycjemex4=""> <span class="attention-viz__mole-word " data-mole-word-index="0" data-mole-context="mole-animal" style="" data-astro-cid-ycjemex4=""> The </span><span class="attention-viz__mole-word " data-mole-word-index="1" data-mole-context="mole-animal" style="" data-astro-cid-ycjemex4=""> American </span><span class="attention-viz__mole-word " data-mole-word-index="2" data-mole-context="mole-animal" style="" data-astro-cid-ycjemex4=""> shrew </span><span class="attention-viz__mole-word attention-viz__mole-word--focus" data-mole-word-index="3" data-mole-context="mole-animal" style="color: #34d399" data-astro-cid-ycjemex4=""> mole </span><span class="attention-viz__mole-word " data-mole-word-index="4" data-mole-context="mole-animal" style="" data-astro-cid-ycjemex4=""> burrows </span><span class="attention-viz__mole-word " data-mole-word-index="5" data-mole-context="mole-animal" style="" data-astro-cid-ycjemex4=""> underground </span> </div> </div> </div><div class="attention-viz__mole-card" id="mole-chemistry" data-mole-card="chemistry" data-astro-cid-ycjemex4=""> <span class="attention-viz__mole-label" style="color: #fbbf24" data-astro-cid-ycjemex4="">Chemistry</span> <div class="attention-viz__mole-sentence-wrap" data-astro-cid-ycjemex4=""> <svg class="attention-viz__mole-arcs" data-mole-arcs="mole-chemistry" viewBox="0 0 560 100" preserveAspectRatio="xMidYMid meet" aria-hidden="true" data-astro-cid-ycjemex4=""> <!-- Arcs drawn by script --> </svg> <div class="attention-viz__mole-words" data-mole-words="mole-chemistry" data-astro-cid-ycjemex4=""> <span class="attention-viz__mole-word " data-mole-word-index="0" data-mole-context="mole-chemistry" style="" data-astro-cid-ycjemex4=""> One </span><span class="attention-viz__mole-word attention-viz__mole-word--focus" data-mole-word-index="1" data-mole-context="mole-chemistry" style="color: #fbbf24" data-astro-cid-ycjemex4=""> mole </span><span class="attention-viz__mole-word " data-mole-word-index="2" data-mole-context="mole-chemistry" style="" data-astro-cid-ycjemex4=""> of </span><span class="attention-viz__mole-word " data-mole-word-index="3" data-mole-context="mole-chemistry" style="" data-astro-cid-ycjemex4=""> CO₂ </span><span class="attention-viz__mole-word " data-mole-word-index="4" data-mole-context="mole-chemistry" style="" data-astro-cid-ycjemex4=""> weighs </span><span class="attention-viz__mole-word " data-mole-word-index="5" data-mole-context="mole-chemistry" style="" data-astro-cid-ycjemex4=""> 44 </span><span class="attention-viz__mole-word " data-mole-word-index="6" data-mole-context="mole-chemistry" style="" data-astro-cid-ycjemex4=""> grams </span> </div> </div> </div><div class="attention-viz__mole-card" id="mole-medical" data-mole-card="medical" data-astro-cid-ycjemex4=""> <span class="attention-viz__mole-label" style="color: #fb7185" data-astro-cid-ycjemex4="">Medical</span> <div class="attention-viz__mole-sentence-wrap" data-astro-cid-ycjemex4=""> <svg class="attention-viz__mole-arcs" data-mole-arcs="mole-medical" viewBox="0 0 560 100" preserveAspectRatio="xMidYMid meet" aria-hidden="true" data-astro-cid-ycjemex4=""> <!-- Arcs drawn by script --> </svg> <div class="attention-viz__mole-words" data-mole-words="mole-medical" data-astro-cid-ycjemex4=""> <span class="attention-viz__mole-word " data-mole-word-index="0" data-mole-context="mole-medical" style="" data-astro-cid-ycjemex4=""> Biopsy </span><span class="attention-viz__mole-word " data-mole-word-index="1" data-mole-context="mole-medical" style="" data-astro-cid-ycjemex4=""> of </span><span class="attention-viz__mole-word " data-mole-word-index="2" data-mole-context="mole-medical" style="" data-astro-cid-ycjemex4=""> the </span><span class="attention-viz__mole-word " data-mole-word-index="3" data-mole-context="mole-medical" style="" data-astro-cid-ycjemex4=""> skin </span><span class="attention-viz__mole-word attention-viz__mole-word--focus" data-mole-word-index="4" data-mole-context="mole-medical" style="color: #fb7185" data-astro-cid-ycjemex4=""> mole </span><span class="attention-viz__mole-word " data-mole-word-index="5" data-mole-context="mole-medical" style="" data-astro-cid-ycjemex4=""> was </span><span class="attention-viz__mole-word " data-mole-word-index="6" data-mole-context="mole-medical" style="" data-astro-cid-ycjemex4=""> benign </span> </div> </div> </div> </div> </div> </div> </section>  <script>(function(){const sentence = ["The","animal","didn't","cross","the","street","because","it","was","too","tired"];
const attentionFromIt = [{"target":0,"weight":0.04},{"target":1,"weight":0.72},{"target":2,"weight":0.03},{"target":3,"weight":0.02},{"target":4,"weight":0.02},{"target":5,"weight":0.05},{"target":6,"weight":0.04},{"target":8,"weight":0.03},{"target":9,"weight":0.02},{"target":10,"weight":0.03}];
const moleContexts = [{"id":"mole-animal","sentence":["The","American","shrew","mole","burrows","underground"],"focus":3,"attentions":[{"target":1,"weight":0.3},{"target":2,"weight":0.45},{"target":4,"weight":0.12},{"target":5,"weight":0.08},{"target":0,"weight":0.05}],"label":"Animal","color":"#34d399"},{"id":"mole-chemistry","sentence":["One","mole","of","CO₂","weighs","44","grams"],"focus":1,"attentions":[{"target":0,"weight":0.25},{"target":3,"weight":0.4},{"target":5,"weight":0.15},{"target":6,"weight":0.1},{"target":2,"weight":0.05},{"target":4,"weight":0.05}],"label":"Chemistry","color":"#fbbf24"},{"id":"mole-medical","sentence":["Biopsy","of","the","skin","mole","was","benign"],"focus":4,"attentions":[{"target":0,"weight":0.35},{"target":3,"weight":0.3},{"target":6,"weight":0.18},{"target":5,"weight":0.07},{"target":1,"weight":0.05},{"target":2,"weight":0.05}],"label":"Medical","color":"#fb7185"}];

  /**
   * AttentionViz — draws SVG arcs for attention weights.
   *
   * GSAP targets:
   *   - [data-attention-block="pronoun"] : pronoun resolution block (opacity)
   *   - .attention-viz__arcs path        : individual arc paths (strokeDashoffset animation)
   *   - [data-attention-qkv]             : QKV explanation block (opacity)
   *   - [data-qkv="query|key|value"]     : individual QKV cards (opacity, y)
   *   - [data-attention-block="mole"]    : mole section block (opacity)
   *   - [data-mole-card]                 : individual mole cards (opacity, y)
   */

  function drawArc(svg, x1, x2, weight, color, maxHeight) {
    const midX = (x1 + x2) / 2;
    const height = Math.abs(x2 - x1) * 0.4 * Math.min(weight * 2, 1);
    const controlY = Math.max(maxHeight - height - 20, 10);

    const path = document.createElementNS('http://www.w3.org/2000/svg', 'path');
    const d = `M ${x1} ${maxHeight - 10} Q ${midX} ${controlY} ${x2} ${maxHeight - 10}`;
    path.setAttribute('d', d);
    path.setAttribute('fill', 'none');
    path.setAttribute('stroke', color);
    path.setAttribute('stroke-width', String(Math.max(weight * 5, 0.5)));
    path.setAttribute('stroke-opacity', String(Math.max(weight * 0.9, 0.08)));
    path.setAttribute('stroke-linecap', 'round');

    // Set up for dash animation
    const length = path.getTotalLength ? path.getTotalLength() : 300;
    path.style.strokeDasharray = String(length);
    path.style.strokeDashoffset = String(length);

    path.setAttribute('data-attention-arc', '');
    path.setAttribute('aria-hidden', 'true');

    svg.appendChild(path);
    return path;
  }

  function initAttentionViz() {
    const gsapLib = (window as any).gsap;
    const ScrollTrigger = (window as any).ScrollTrigger;

    // ---- Draw pronoun resolution arcs ----
    const arcsSvg = document.getElementById('attention-arcs-svg');
    const wordsContainer = document.getElementById('attention-words');

    if (arcsSvg && wordsContainer) {
      const words = wordsContainer.querySelectorAll('.attention-viz__word');
      const wordCount = words.length;

      // Calculate positions based on even spacing in the SVG viewBox (880 wide)
      const svgWidth = 880;
      const svgHeight = 160;
      const padding = 40;
      const spacing = (svgWidth - 2 * padding) / (wordCount - 1);

      const sourceIndex = 7; // "it"
      const sourceX = padding + sourceIndex * spacing;

      attentionFromIt.forEach((att) => {
        const targetX = padding + att.target * spacing;
        const color = att.weight > 0.5 ? '#fbbf24' : '#38bdf8';
        drawArc(arcsSvg, sourceX, targetX, att.weight, color, svgHeight);
      });
    }

    // ---- Draw mole arcs ----
    moleContexts.forEach((ctx) => {
      const moleSvg = document.querySelector(`[data-mole-arcs="${ctx.id}"]`);
      if (!moleSvg) return;

      const moleWordCount = ctx.sentence.length;
      const svgWidth = 560;
      const svgHeight = 100;
      const padding = 30;
      const spacing = (svgWidth - 2 * padding) / (moleWordCount - 1);
      const focusX = padding + ctx.focus * spacing;

      ctx.attentions.forEach((att) => {
        const targetX = padding + att.target * spacing;
        drawArc(moleSvg, focusX, targetX, att.weight, ctx.color, svgHeight);
      });
    });

    // ---- GSAP animations ----
    if (!gsapLib || !ScrollTrigger) {
      // Fallback: show everything
      document.querySelectorAll('.attention-viz__block, .attention-viz__qkv, .attention-viz__mole-card').forEach((el) => {
        (el as HTMLElement).style.opacity = '1';
      });
      document.querySelectorAll('[data-attention-arc]').forEach((path) => {
        (path as SVGPathElement).style.strokeDashoffset = '0';
      });
      return;
    }

    const prefersReduced = window.matchMedia('(prefers-reduced-motion: reduce)').matches;
    const section = document.getElementById('attention-viz-section');
    if (!section) return;

    // Set initial states via GSAP (progressive enhancement — content visible without JS)
    gsapLib.set('.attention-viz__block', { opacity: 0 });
    gsapLib.set('.attention-viz__qkv', { opacity: 0 });
    gsapLib.set('.attention-viz__mole-card', { opacity: 0 });

    // Pronoun block reveal
    const pronounBlock = section.querySelector('[data-attention-block="pronoun"]');
    const pronounArcs = section.querySelectorAll('#attention-arcs-svg [data-attention-arc]');

    const tl1 = gsapLib.timeline({
      scrollTrigger: {
        trigger: pronounBlock,
        start: 'top 75%',
        toggleActions: 'play none none reverse',
      },
    });

    tl1.to(pronounBlock, { opacity: 1, duration: prefersReduced ? 0.2 : 0.5 });

    if (!prefersReduced) {
      tl1.to(pronounArcs, {
        strokeDashoffset: 0,
        duration: 0.6,
        stagger: 0.05,
        ease: 'power2.inOut',
      }, '-=0.2');
    } else {
      tl1.to(pronounArcs, { strokeDashoffset: 0, duration: 0.1, stagger: 0 }, '<');
    }

    // QKV cards
    const qkvBlock = section.querySelector('[data-attention-qkv]');
    const qkvCards = section.querySelectorAll('[data-qkv]');

    const tl2 = gsapLib.timeline({
      scrollTrigger: {
        trigger: qkvBlock,
        start: 'top 78%',
        toggleActions: 'play none none reverse',
      },
    });

    if (!prefersReduced) {
      gsapLib.set(qkvCards, { y: 16 });
    }

    tl2.to(qkvBlock, { opacity: 1, duration: prefersReduced ? 0.2 : 0.4 })
      .to(qkvCards, {
        opacity: 1,
        y: 0,
        duration: prefersReduced ? 0.1 : 0.4,
        stagger: prefersReduced ? 0 : 0.12,
        ease: 'power2.out',
      }, prefersReduced ? '<' : '-=0.1');

    // Mole block and cards
    const moleBlock = section.querySelector('[data-attention-block="mole"]');
    const moleCards = section.querySelectorAll('[data-mole-card]');
    const moleArcs = section.querySelectorAll('.attention-viz__mole-arcs [data-attention-arc]');

    const tl3 = gsapLib.timeline({
      scrollTrigger: {
        trigger: moleBlock,
        start: 'top 75%',
        toggleActions: 'play none none reverse',
      },
    });

    if (!prefersReduced) {
      gsapLib.set(moleCards, { y: 20 });
    }

    tl3.to(moleBlock, { opacity: 1, duration: prefersReduced ? 0.2 : 0.5 })
      .to(moleCards, {
        opacity: 1,
        y: 0,
        duration: prefersReduced ? 0.1 : 0.45,
        stagger: prefersReduced ? 0 : 0.15,
        ease: 'power2.out',
      }, prefersReduced ? '<' : '-=0.2')
      .to(moleArcs, {
        strokeDashoffset: 0,
        duration: prefersReduced ? 0.1 : 0.5,
        stagger: prefersReduced ? 0 : 0.03,
        ease: 'power2.inOut',
      }, prefersReduced ? '<' : '-=0.3');
  }

  if (document.readyState === 'loading') {
    document.addEventListener('DOMContentLoaded', initAttentionViz);
  } else {
    initAttentionViz();
  }
})();</script> <!-- NEURAL NETWORK / TRANSFORMER --> <div class="chapter-divider" id="ch-transformer" data-astro-cid-j7pv25f6=""> <span class="chapter-number" data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 15px); opacity: 0;">Putting It Together</span> <h2 data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 20px); opacity: 0;">The Transformer Architecture</h2> <p data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 15px); opacity: 0;">
Tokenization, embeddings, and attention combine inside a
        transformer — the architecture introduced in Google's landmark 2017
        paper "Attention Is All You Need" that powers every modern LLM.
</p> </div> <p class="viz-instruction" data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 10px); opacity: 0;">Scroll to open the black box</p> <div class="pin-spacer" style="order: 0; place-self: auto; grid-area: auto; z-index: auto; float: none; flex-shrink: 1; display: flex; margin: 0px; inset: 0px; position: relative; flex-basis: auto; overflow: visible; box-sizing: border-box; width: 1274px; height: 2299px; padding: 0px 0px 1398px;"><section id="neural-network-section" class="nn-section" aria-label="Neural network transformer architecture" data-astro-cid-ogotf4fw="" style="translate: none; rotate: none; scale: none; inset: 0px auto auto 0px; margin: 0px; max-width: 1274px; width: 1274px; max-height: 901.448px; height: 901.448px; padding: 64px 24px; transform: translate(0px, 0px);"> <div class="nn-container" data-astro-cid-ogotf4fw=""> <div class="nn-text-content" data-astro-cid-ogotf4fw=""> <h2 class="nn-heading" data-nn="heading" data-astro-cid-ogotf4fw="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 20px); opacity: 0;">The LLM: a black box?</h2> <p class="nn-description" data-nn="desc" data-astro-cid-ogotf4fw="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 20px); opacity: 0;">
GPT-4 has an estimated <strong data-astro-cid-ogotf4fw="">1.8 trillion parameters</strong> — numerical
        values learned during training. That’s why it’s called a “black box”:
        no human could unravel all those connections. But we <em data-astro-cid-ogotf4fw="">can</em>
understand the architecture. Let’s open the box.
</p> </div> <div class="nn-layout" data-nn="layout" data-astro-cid-ogotf4fw=""> <div class="nn-viz-wrapper" data-nn="viz-wrapper" data-astro-cid-ogotf4fw=""> <!-- SVG circle mask overlay --> <div class="nn-blackbox-overlay" data-nn="blackbox" aria-hidden="true" data-astro-cid-ogotf4fw="" style="pointer-events: auto;"> <svg class="nn-mask-svg" viewBox="0 0 900 560" preserveAspectRatio="xMidYSlice meet" data-astro-cid-ogotf4fw=""> <defs data-astro-cid-ogotf4fw=""> <mask id="nn-reveal-mask" maskUnits="userSpaceOnUse" x="0" y="0" width="900" height="560" data-astro-cid-ogotf4fw=""> <rect width="900" height="560" fill="white" data-astro-cid-ogotf4fw=""></rect> <circle id="nn-reveal-circle" cx="450" cy="280" r="0" fill="black" data-astro-cid-ogotf4fw=""></circle> </mask> <radialgradient id="nn-mask-edge-grad" data-astro-cid-ogotf4fw=""> <stop offset="85%" stop-color="black" data-astro-cid-ogotf4fw=""></stop> <stop offset="100%" stop-color="white" data-astro-cid-ogotf4fw=""></stop> </radialgradient> </defs> <!-- Dark overlay with circle cut out --> <rect width="900" height="560" fill="rgba(225, 238, 243, 0.97)" mask="url(#nn-reveal-mask)" data-astro-cid-ogotf4fw=""></rect> </svg> <span class="nn-blackbox-label" data-nn="blackbox-label" data-astro-cid-ogotf4fw="">?</span> </div> <svg id="nn-svg" class="nn-svg" viewBox="0 0 900 560" xmlns="http://www.w3.org/2000/svg" role="img" aria-label="Transformer architecture diagram showing input tokens flowing through embedding, self-attention, feed-forward layers, and output softmax to produce next-token predictions" data-astro-cid-ogotf4fw=""> <defs data-astro-cid-ogotf4fw=""> <!-- Glow filter for nodes --> <filter id="nn-glow" x="-50%" y="-50%" width="200%" height="200%" data-astro-cid-ogotf4fw=""> <fegaussianblur in="SourceGraphic" stdDeviation="3" result="blur" data-astro-cid-ogotf4fw=""></fegaussianblur> <fecomposite in="SourceGraphic" in2="blur" operator="over" data-astro-cid-ogotf4fw=""></fecomposite> </filter> <!-- Stronger glow for active pulses --> <filter id="nn-pulse-glow" x="-100%" y="-100%" width="300%" height="300%" data-astro-cid-ogotf4fw=""> <fegaussianblur in="SourceGraphic" stdDeviation="6" result="blur" data-astro-cid-ogotf4fw=""></fegaussianblur> <femerge data-astro-cid-ogotf4fw=""> <femergenode in="blur" data-astro-cid-ogotf4fw=""></femergenode> <femergenode in="SourceGraphic" data-astro-cid-ogotf4fw=""></femergenode> </femerge> </filter> <!-- Gradient for connection lines --> <lineargradient id="nn-conn-grad" x1="0%" y1="0%" x2="100%" y2="0%" data-astro-cid-ogotf4fw=""> <stop offset="0%" stop-color="#0ea5e9" stop-opacity="0.15" data-astro-cid-ogotf4fw=""></stop> <stop offset="50%" stop-color="#0ea5e9" stop-opacity="0.4" data-astro-cid-ogotf4fw=""></stop> <stop offset="100%" stop-color="#0ea5e9" stop-opacity="0.15" data-astro-cid-ogotf4fw=""></stop> </lineargradient> <!-- Gradient for attention block --> <lineargradient id="nn-attn-grad" x1="0%" y1="0%" x2="0%" y2="100%" data-astro-cid-ogotf4fw=""> <stop offset="0%" stop-color="#0ea5e9" stop-opacity="0.12" data-astro-cid-ogotf4fw=""></stop> <stop offset="100%" stop-color="#06b6d4" stop-opacity="0.06" data-astro-cid-ogotf4fw=""></stop> </lineargradient> <!-- Gradient for FFN block --> <lineargradient id="nn-ffn-grad" x1="0%" y1="0%" x2="0%" y2="100%" data-astro-cid-ogotf4fw=""> <stop offset="0%" stop-color="#8b5cf6" stop-opacity="0.12" data-astro-cid-ogotf4fw=""></stop> <stop offset="100%" stop-color="#7c3aed" stop-opacity="0.06" data-astro-cid-ogotf4fw=""></stop> </lineargradient> <!-- Data flow pulse gradient --> <radialgradient id="nn-data-pulse" data-astro-cid-ogotf4fw=""> <stop offset="0%" stop-color="#00d4ff" stop-opacity="1" data-astro-cid-ogotf4fw=""></stop> <stop offset="60%" stop-color="#0ea5e9" stop-opacity="0.6" data-astro-cid-ogotf4fw=""></stop> <stop offset="100%" stop-color="#0ea5e9" stop-opacity="0" data-astro-cid-ogotf4fw=""></stop> </radialgradient> <!-- Arrow marker --> <marker id="nn-arrow" viewBox="0 0 10 10" refX="9" refY="5" markerWidth="6" markerHeight="6" orient="auto-start-reverse" data-astro-cid-ogotf4fw=""> <path d="M 0 0 L 10 5 L 0 10 z" fill="#0ea5e9" opacity="0.5" data-astro-cid-ogotf4fw=""></path> </marker> </defs> <!-- ===== LAYER 1: INPUT TOKENS ===== --> <g data-nn-layer="input" class="nn-layer" opacity="0" data-astro-cid-ogotf4fw=""> <text x="400" y="538" class="nn-layer-label" text-anchor="middle" data-astro-cid-ogotf4fw="">Input</text> <text x="400" y="552" class="nn-layer-sublabel" text-anchor="middle" data-astro-cid-ogotf4fw="">Tokens</text> <g class="nn-token-group" data-astro-cid-ogotf4fw=""> <rect x="275" y="492" width="50" height="30" rx="4" class="nn-token-box" data-nn-node="input-0" data-astro-cid-ogotf4fw=""></rect> <text x="300" y="512" class="nn-token-text" text-anchor="middle" data-astro-cid-ogotf4fw="">The</text> </g> <g class="nn-token-group" data-astro-cid-ogotf4fw=""> <rect x="375" y="492" width="50" height="30" rx="4" class="nn-token-box" data-nn-node="input-1" data-astro-cid-ogotf4fw=""></rect> <text x="400" y="512" class="nn-token-text" text-anchor="middle" data-astro-cid-ogotf4fw="">cat</text> </g> <g class="nn-token-group" data-astro-cid-ogotf4fw=""> <rect x="475" y="492" width="50" height="30" rx="4" class="nn-token-box" data-nn-node="input-2" data-astro-cid-ogotf4fw=""></rect> <text x="500" y="512" class="nn-token-text" text-anchor="middle" data-astro-cid-ogotf4fw="">sat</text> </g> </g> <!-- ===== LAYER 2: EMBEDDING ===== --> <g data-nn-layer="embedding" class="nn-layer" opacity="0" data-astro-cid-ogotf4fw=""> <text x="400" y="454" class="nn-layer-label" text-anchor="middle" data-astro-cid-ogotf4fw="">Embedding</text> <circle cx="300" cy="466" r="10" class="nn-node nn-node-embed" data-nn-node="embed-0" data-astro-cid-ogotf4fw=""></circle> <circle cx="400" cy="466" r="10" class="nn-node nn-node-embed" data-nn-node="embed-1" data-astro-cid-ogotf4fw=""></circle> <circle cx="500" cy="466" r="10" class="nn-node nn-node-embed" data-nn-node="embed-2" data-astro-cid-ogotf4fw=""></circle> <line x1="300" y1="492" x2="300" y2="476" class="nn-connection" data-nn-conn="input-embed" data-astro-cid-ogotf4fw=""></line> <line x1="400" y1="492" x2="400" y2="476" class="nn-connection" data-nn-conn="input-embed" data-astro-cid-ogotf4fw=""></line> <line x1="500" y1="492" x2="500" y2="476" class="nn-connection" data-nn-conn="input-embed" data-astro-cid-ogotf4fw=""></line> </g> <!-- ===== TRANSFORMER BLOCK 1 ===== --> <g data-nn-layer="transformer-1" class="nn-layer nn-transformer-block" opacity="0" data-astro-cid-ogotf4fw=""> <rect x="180" y="276" width="440" height="168" rx="8" class="nn-block-bg" data-astro-cid-ogotf4fw=""></rect> <text x="632" y="340" class="nn-block-label" data-astro-cid-ogotf4fw="">Transformer</text> <text x="632" y="358" class="nn-block-label" data-astro-cid-ogotf4fw="">Block 1</text> <!-- Self-Attention sub-block: label at top, nodes below --> <rect x="195" y="358" width="410" height="76" rx="6" class="nn-attn-block" data-astro-cid-ogotf4fw=""></rect> <text x="400" y="376" class="nn-sublayer-label" text-anchor="middle" data-astro-cid-ogotf4fw="">Self-Attention</text> <circle cx="300" cy="414" r="8" class="nn-node nn-node-attn" data-nn-node="attn1-0" data-astro-cid-ogotf4fw=""></circle> <circle cx="400" cy="414" r="8" class="nn-node nn-node-attn" data-nn-node="attn1-1" data-astro-cid-ogotf4fw=""></circle> <circle cx="500" cy="414" r="8" class="nn-node nn-node-attn" data-nn-node="attn1-2" data-astro-cid-ogotf4fw=""></circle> <line x1="300" y1="414" x2="400" y2="414" class="nn-attention-link" data-astro-cid-ogotf4fw=""></line> <line x1="400" y1="414" x2="500" y2="414" class="nn-attention-link" data-astro-cid-ogotf4fw=""></line> <line x1="300" y1="414" x2="500" y2="414" class="nn-attention-link" data-astro-cid-ogotf4fw=""></line> <!-- Feed-Forward sub-block: label at top, nodes below --> <rect x="195" y="282" width="410" height="66" rx="6" class="nn-ffn-block" data-astro-cid-ogotf4fw=""></rect> <text x="400" y="302" class="nn-sublayer-label" text-anchor="middle" data-astro-cid-ogotf4fw="">Feed-Forward (MLP)</text> <circle cx="270" cy="332" r="8" class="nn-node nn-node-ffn" data-nn-node="ffn1-0" data-astro-cid-ogotf4fw=""></circle> <circle cx="360" cy="332" r="8" class="nn-node nn-node-ffn" data-nn-node="ffn1-1" data-astro-cid-ogotf4fw=""></circle> <circle cx="450" cy="332" r="8" class="nn-node nn-node-ffn" data-nn-node="ffn1-2" data-astro-cid-ogotf4fw=""></circle> <circle cx="540" cy="332" r="8" class="nn-node nn-node-ffn" data-nn-node="ffn1-3" data-astro-cid-ogotf4fw=""></circle> <!-- Internal connections: attention -> FFN --> <line x1="300" y1="406" x2="270" y2="340" class="nn-connection nn-internal" data-astro-cid-ogotf4fw=""></line> <line x1="300" y1="406" x2="360" y2="340" class="nn-connection nn-internal" data-astro-cid-ogotf4fw=""></line> <line x1="400" y1="406" x2="360" y2="340" class="nn-connection nn-internal" data-astro-cid-ogotf4fw=""></line> <line x1="400" y1="406" x2="450" y2="340" class="nn-connection nn-internal" data-astro-cid-ogotf4fw=""></line> <line x1="500" y1="406" x2="450" y2="340" class="nn-connection nn-internal" data-astro-cid-ogotf4fw=""></line> <line x1="500" y1="406" x2="540" y2="340" class="nn-connection nn-internal" data-astro-cid-ogotf4fw=""></line> <!-- Connections from embedding to attention --> <line x1="300" y1="456" x2="300" y2="422" class="nn-connection" data-nn-conn="embed-attn1" data-astro-cid-ogotf4fw=""></line> <line x1="400" y1="456" x2="400" y2="422" class="nn-connection" data-nn-conn="embed-attn1" data-astro-cid-ogotf4fw=""></line> <line x1="500" y1="456" x2="500" y2="422" class="nn-connection" data-nn-conn="embed-attn1" data-astro-cid-ogotf4fw=""></line> </g> <!-- ===== TRANSFORMER BLOCK 2 ===== --> <g data-nn-layer="transformer-2" class="nn-layer nn-transformer-block" opacity="0" data-astro-cid-ogotf4fw=""> <rect x="180" y="96" width="440" height="168" rx="8" class="nn-block-bg" data-astro-cid-ogotf4fw=""></rect> <text x="632" y="160" class="nn-block-label" data-astro-cid-ogotf4fw="">Transformer</text> <text x="632" y="178" class="nn-block-label" data-astro-cid-ogotf4fw="">Block 2</text> <rect x="195" y="178" width="410" height="76" rx="6" class="nn-attn-block" data-astro-cid-ogotf4fw=""></rect> <text x="400" y="196" class="nn-sublayer-label" text-anchor="middle" data-astro-cid-ogotf4fw="">Self-Attention</text> <circle cx="300" cy="234" r="8" class="nn-node nn-node-attn" data-nn-node="attn2-0" data-astro-cid-ogotf4fw=""></circle> <circle cx="400" cy="234" r="8" class="nn-node nn-node-attn" data-nn-node="attn2-1" data-astro-cid-ogotf4fw=""></circle> <circle cx="500" cy="234" r="8" class="nn-node nn-node-attn" data-nn-node="attn2-2" data-astro-cid-ogotf4fw=""></circle> <line x1="300" y1="234" x2="400" y2="234" class="nn-attention-link" data-astro-cid-ogotf4fw=""></line> <line x1="400" y1="234" x2="500" y2="234" class="nn-attention-link" data-astro-cid-ogotf4fw=""></line> <line x1="300" y1="234" x2="500" y2="234" class="nn-attention-link" data-astro-cid-ogotf4fw=""></line> <rect x="195" y="102" width="410" height="66" rx="6" class="nn-ffn-block" data-astro-cid-ogotf4fw=""></rect> <text x="400" y="122" class="nn-sublayer-label" text-anchor="middle" data-astro-cid-ogotf4fw="">Feed-Forward (MLP)</text> <circle cx="270" cy="152" r="8" class="nn-node nn-node-ffn" data-nn-node="ffn2-0" data-astro-cid-ogotf4fw=""></circle> <circle cx="360" cy="152" r="8" class="nn-node nn-node-ffn" data-nn-node="ffn2-1" data-astro-cid-ogotf4fw=""></circle> <circle cx="450" cy="152" r="8" class="nn-node nn-node-ffn" data-nn-node="ffn2-2" data-astro-cid-ogotf4fw=""></circle> <circle cx="540" cy="152" r="8" class="nn-node nn-node-ffn" data-nn-node="ffn2-3" data-astro-cid-ogotf4fw=""></circle> <line x1="300" y1="226" x2="270" y2="160" class="nn-connection nn-internal" data-astro-cid-ogotf4fw=""></line> <line x1="300" y1="226" x2="360" y2="160" class="nn-connection nn-internal" data-astro-cid-ogotf4fw=""></line> <line x1="400" y1="226" x2="360" y2="160" class="nn-connection nn-internal" data-astro-cid-ogotf4fw=""></line> <line x1="400" y1="226" x2="450" y2="160" class="nn-connection nn-internal" data-astro-cid-ogotf4fw=""></line> <line x1="500" y1="226" x2="450" y2="160" class="nn-connection nn-internal" data-astro-cid-ogotf4fw=""></line> <line x1="500" y1="226" x2="540" y2="160" class="nn-connection nn-internal" data-astro-cid-ogotf4fw=""></line> <!-- Connections from block 1 FFN to block 2 attention --> <line x1="270" y1="276" x2="300" y2="242" class="nn-connection" data-nn-conn="ffn1-attn2" data-astro-cid-ogotf4fw=""></line> <line x1="400" y1="276" x2="400" y2="242" class="nn-connection" data-nn-conn="ffn1-attn2" data-astro-cid-ogotf4fw=""></line> <line x1="540" y1="276" x2="500" y2="242" class="nn-connection" data-nn-conn="ffn1-attn2" data-astro-cid-ogotf4fw=""></line> </g> <!-- ===== Nx label ===== --> <g data-nn-layer="transformer-2" class="nn-layer" opacity="0" data-astro-cid-ogotf4fw=""> <text x="640" y="245" class="nn-nx-label" data-astro-cid-ogotf4fw="">×N</text> <text x="640" y="263" class="nn-nx-sublabel" data-astro-cid-ogotf4fw="">layers</text> </g> <!-- ===== OUTPUT LAYER ===== --> <g data-nn-layer="output" class="nn-layer" opacity="0" data-astro-cid-ogotf4fw=""> <line x1="270" y1="96" x2="300" y2="86" class="nn-connection" data-nn-conn="ffn2-output" data-astro-cid-ogotf4fw=""></line> <line x1="360" y1="96" x2="370" y2="86" class="nn-connection" data-nn-conn="ffn2-output" data-astro-cid-ogotf4fw=""></line> <line x1="450" y1="96" x2="440" y2="86" class="nn-connection" data-nn-conn="ffn2-output" data-astro-cid-ogotf4fw=""></line> <line x1="540" y1="96" x2="510" y2="86" class="nn-connection" data-nn-conn="ffn2-output" data-astro-cid-ogotf4fw=""></line> <rect x="250" y="50" width="300" height="36" rx="6" class="nn-output-block" data-astro-cid-ogotf4fw=""></rect> <text x="400" y="74" class="nn-sublayer-label nn-output-label" text-anchor="middle" data-astro-cid-ogotf4fw="">Softmax → Next Token</text> <g class="nn-prob-group" data-nn="probs" data-astro-cid-ogotf4fw=""> <rect x="700" y="30" width="8" height="46" rx="2" class="nn-prob-bar" data-nn-prob="0" opacity="0" data-astro-cid-ogotf4fw=""></rect> <text x="704" y="88" class="nn-prob-text" text-anchor="middle" opacity="0" data-astro-cid-ogotf4fw="">on</text> <rect x="730" y="55" width="8" height="21" rx="2" class="nn-prob-bar" data-nn-prob="1" opacity="0" data-astro-cid-ogotf4fw=""></rect> <text x="734" y="88" class="nn-prob-text" text-anchor="middle" opacity="0" data-astro-cid-ogotf4fw="">by</text> <rect x="760" y="62" width="8" height="14" rx="2" class="nn-prob-bar" data-nn-prob="2" opacity="0" data-astro-cid-ogotf4fw=""></rect> <text x="764" y="88" class="nn-prob-text" text-anchor="middle" opacity="0" data-astro-cid-ogotf4fw="">in</text> <rect x="790" y="66" width="8" height="10" rx="2" class="nn-prob-bar" data-nn-prob="3" opacity="0" data-astro-cid-ogotf4fw=""></rect> <text x="794" y="88" class="nn-prob-text" text-anchor="middle" opacity="0" data-astro-cid-ogotf4fw="">at</text> <text x="745" y="22" class="nn-prob-heading" text-anchor="middle" opacity="0" data-astro-cid-ogotf4fw="">Predicted next token</text> <line x1="550" y1="68" x2="690" y2="68" class="nn-connection nn-output-conn" marker-end="url(#nn-arrow)" opacity="0" data-astro-cid-ogotf4fw=""></line> </g> </g> <!-- ===== DATA FLOW PULSES ===== --> <g data-nn="pulses" aria-hidden="true" data-astro-cid-ogotf4fw=""> <circle r="5" class="nn-pulse" data-nn-pulse="0" opacity="0" fill="url(#nn-data-pulse)" filter="url(#nn-pulse-glow)" data-astro-cid-ogotf4fw=""></circle> <circle r="5" class="nn-pulse" data-nn-pulse="1" opacity="0" fill="url(#nn-data-pulse)" filter="url(#nn-pulse-glow)" data-astro-cid-ogotf4fw=""></circle> <circle r="5" class="nn-pulse" data-nn-pulse="2" opacity="0" fill="url(#nn-data-pulse)" filter="url(#nn-pulse-glow)" data-astro-cid-ogotf4fw=""></circle> </g> </svg> </div> <!-- KEY / LEGEND --> <div class="nn-key" data-nn="key" data-astro-cid-ogotf4fw=""> <h3 class="nn-key-title" data-astro-cid-ogotf4fw="">Architecture Key</h3> <div class="nn-key-item" data-nn-key="input" data-astro-cid-ogotf4fw=""> <div class="nn-key-dot nn-key-dot--input" data-astro-cid-ogotf4fw=""></div> <div data-astro-cid-ogotf4fw=""> <span class="nn-key-label" data-astro-cid-ogotf4fw="">Input Tokens</span> <span class="nn-key-desc" data-astro-cid-ogotf4fw="">Text broken into pieces the model can process</span> </div> </div> <div class="nn-key-item" data-nn-key="embedding" data-astro-cid-ogotf4fw=""> <div class="nn-key-dot nn-key-dot--embed" data-astro-cid-ogotf4fw=""></div> <div data-astro-cid-ogotf4fw=""> <span class="nn-key-label" data-astro-cid-ogotf4fw="">Embedding</span> <span class="nn-key-desc" data-astro-cid-ogotf4fw="">Each token becomes a vector of ~12,000 numbers</span> </div> </div> <div class="nn-key-item" data-nn-key="attention" data-astro-cid-ogotf4fw=""> <div class="nn-key-dot nn-key-dot--attn" data-astro-cid-ogotf4fw=""></div> <div data-astro-cid-ogotf4fw=""> <span class="nn-key-label" data-astro-cid-ogotf4fw="">Self-Attention</span> <span class="nn-key-desc" data-astro-cid-ogotf4fw="">Every word looks at every other word for context</span> </div> </div> <div class="nn-key-item" data-nn-key="ffn" data-astro-cid-ogotf4fw=""> <div class="nn-key-dot nn-key-dot--ffn" data-astro-cid-ogotf4fw=""></div> <div data-astro-cid-ogotf4fw=""> <span class="nn-key-label" data-astro-cid-ogotf4fw="">Feed-Forward (MLP)</span> <span class="nn-key-desc" data-astro-cid-ogotf4fw="">Dense neural network layers that transform representations</span> </div> </div> <div class="nn-key-item" data-nn-key="output" data-astro-cid-ogotf4fw=""> <div class="nn-key-dot nn-key-dot--output" data-astro-cid-ogotf4fw=""></div> <div data-astro-cid-ogotf4fw=""> <span class="nn-key-label" data-astro-cid-ogotf4fw="">Softmax Output</span> <span class="nn-key-desc" data-astro-cid-ogotf4fw="">Probability distribution over every possible next token</span> </div> </div> <div class="nn-key-callout" data-nn-key="params" data-astro-cid-ogotf4fw=""> <strong data-astro-cid-ogotf4fw="">GPT-4: ~1.8 trillion parameters</strong> <span data-astro-cid-ogotf4fw="">96 transformer layers, each with billions of learned numerical connections.
        This is why it’s a “black box” — the sheer scale makes
        individual connections impossible to trace.</span> </div> </div> </div><!-- /nn-layout --> </div> </section></div>  <script type="module">function B(){const t=window.gsap,q=window.ScrollTrigger;if(!t||!q)return;const e=document.getElementById("neural-network-section");if(!e)return;const d=e.querySelector('[data-nn="heading"]'),y=e.querySelector('[data-nn="desc"]'),f=e.querySelector('[data-nn="blackbox"]'),w=e.querySelector('[data-nn="blackbox-label"]'),g=document.getElementById("nn-reveal-circle"),E=e.querySelectorAll("[data-nn-prob]"),v=e.querySelectorAll(".nn-prob-text"),x=e.querySelector(".nn-prob-heading"),T=e.querySelector(".nn-output-conn"),A=e.querySelectorAll(".nn-pulse"),u=e.querySelector('[data-nn="key"]'),b={input:e.querySelector('[data-nn-key="input"]'),embedding:e.querySelector('[data-nn-key="embedding"]'),attention:e.querySelector('[data-nn-key="attention"]'),ffn:e.querySelector('[data-nn-key="ffn"]'),output:e.querySelector('[data-nn-key="output"]')},s=e.querySelector('[data-nn-key="params"]'),C=["input","embedding","transformer-1","transformer-2","output"],L={input:["input"],embedding:["embedding"],"transformer-1":["attention","ffn"],"transformer-2":["attention","ffn"],output:["output"]},l={};function r(n,o){l[n]||(l[n]=!0,o())}function i(n,o){l[n]&&(l[n]=!1,o())}t.set([d,y],{opacity:0,y:20}),t.set(g,{attr:{r:0}}),f.style.pointerEvents="auto";const H=[507,466,414,332,234,152,68],O=[300,400,500],m=[];A.forEach((n,o)=>{const p=O[o]||O[0],c=t.timeline({repeat:-1,delay:o*.6,paused:!0});H.forEach((h,S)=>{S===0?c.set(n,{attr:{cx:p,cy:h},opacity:.9}):c.to(n,{attr:{cy:h},duration:.4,ease:"power1.inOut"})}),c.to(n,{opacity:0,duration:.2}),m.push(c)}),q.create({trigger:e,start:"center center",end:"+=250%",pin:!0,anticipatePin:1,onUpdate:n=>{const o=n.progress;o>=.02?r("heading",()=>{t.to(d,{opacity:1,y:0,duration:.5,ease:"power2.out"})}):i("heading",()=>{t.to(d,{opacity:0,y:20,duration:.3})}),o>=.05?r("desc",()=>{t.to(y,{opacity:1,y:0,duration:.5,ease:"power2.out"})}):i("desc",()=>{t.to(y,{opacity:0,y:20,duration:.3})}),o>=.1?r("blackbox",()=>{t.to(w,{opacity:0,duration:.3,ease:"power2.in"}),t.to(g,{attr:{r:600},duration:1.2,ease:"power2.inOut",onComplete:()=>{f.style.pointerEvents="none"}}),u&&t.to(u,{opacity:1,duration:.6,delay:.3,ease:"power2.out"})}):i("blackbox",()=>{t.to(g,{attr:{r:0},duration:.6,ease:"power2.in"}),t.to(w,{opacity:1,duration:.3,delay:.3,onComplete:()=>{f.style.pointerEvents="auto"}}),u&&t.to(u,{opacity:0,duration:.3}),Object.values(b).forEach(a=>a?.classList.remove("active")),s&&t.set(s,{opacity:0})});const p=.25,S=(.75-p)/C.length;C.forEach((a,I)=>{const F=p+I*S,P=`layer-${a}`,R=e.querySelectorAll(`[data-nn-layer="${a}"]`);o>=F?r(P,()=>{t.to(R,{opacity:1,duration:.5,stagger:.05,ease:"power2.out"}),(L[a]||[]).forEach(k=>b[k]?.classList.add("active"))}):i(P,()=>{t.to(R,{opacity:0,duration:.3}),(L[a]||[]).forEach(k=>b[k]?.classList.remove("active"))})}),o>=.75?r("output-conn",()=>{t.to(T,{opacity:1,duration:.4,ease:"power2.out"})}):i("output-conn",()=>{t.to(T,{opacity:0,duration:.3})}),o>=.78?r("prob-heading",()=>{t.to(x,{opacity:1,duration:.4,ease:"power2.out"})}):i("prob-heading",()=>{t.to(x,{opacity:0,duration:.3})}),o>=.8?r("prob-bars",()=>{t.to(E,{opacity:1,duration:.4,stagger:.08,ease:"power2.out"})}):i("prob-bars",()=>{t.to(E,{opacity:0,duration:.3})}),o>=.83?r("prob-texts",()=>{t.to(v,{opacity:1,duration:.4,stagger:.08})}):i("prob-texts",()=>{t.to(v,{opacity:0,duration:.3})}),o>=.9?(r("pulses",()=>{m.forEach(a=>a.play())}),r("params-callout",()=>{s&&t.to(s,{opacity:1,duration:.5,ease:"power2.out"})})):(i("pulses",()=>{m.forEach(a=>{a.pause(),a.progress(0)}),t.set(A,{opacity:0})}),i("params-callout",()=>{s&&t.to(s,{opacity:0,duration:.3})}))}})}document.readyState==="loading"?document.addEventListener("DOMContentLoaded",()=>{requestAnimationFrame(B)}):requestAnimationFrame(B);</script> <!-- RLHF --> <div class="chapter-divider" id="ch-rlhf" data-astro-cid-j7pv25f6=""> <span class="chapter-number" data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 15px); opacity: 0;">The Final Step</span> <h2 data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 20px); opacity: 0;">RLHF: Teaching the Model Manners</h2> <p data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 15px); opacity: 0;">
A raw LLM is powerful but unruly — it might generate toxic content,
        confidently state falsehoods, or ignore your actual question. That's
        where <strong data-astro-cid-j7pv25f6="">RLHF</strong> comes in.
</p> </div> <div class="full-section" id="rlhf-section" data-astro-cid-j7pv25f6=""> <h3 id="rlhf-title" data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 20px); opacity: 0;">Reinforcement Learning from Human Feedback</h3> <p id="rlhf-p1" data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 20px); opacity: 0;">
After the base model is trained on trillions of tokens, human reviewers
        step in. They're shown pairs of model outputs and asked: <em data-astro-cid-j7pv25f6="">which
        response is more helpful, more accurate, less harmful?</em> These
        preferences are used to train a <strong data-astro-cid-j7pv25f6="">reward model</strong> — a
        separate system that learns to score outputs the way humans would.
</p> <p id="rlhf-p2" data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 20px); opacity: 0;">
The LLM is then fine-tuned using reinforcement learning to maximise
        that reward score. Over many iterations, the model learns to produce
        responses that are helpful, honest, and safe — not because it
        understands these concepts, but because it's been optimised to match
        human preferences. This is what turns a raw text predictor into a
        usable assistant like ChatGPT or Claude.
</p> <p id="rlhf-p3" style="font-size: 0.95rem; color: var(--text-muted); font-style: italic; translate: none; rotate: none; scale: none; transform: translate(0px, 20px); opacity: 0;" data-astro-cid-j7pv25f6="">
RLHF is the "snowman sculptor" — the process that shapes the raw
        iceberg into the polished application sitting on top.
</p> <p id="rlhf-p4" data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 20px); opacity: 0;">
But there’s a hidden cost. The humans doing this work — many
        employed through outsourcing firms in Kenya, the Philippines, and other
        countries — are often paid less than $2 per hour to review and classify
        content, including violent, sexual, and deeply disturbing material. A 2023
<em data-astro-cid-j7pv25f6="">Time</em> investigation revealed that workers labelling data for ChatGPT
        described the work as “torture.” This is the invisible human
        labour that makes AI “alignment” possible.
</p> <blockquote class="pull-quote" id="crawford-quote" data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 20px); opacity: 0;"> <p data-astro-cid-j7pv25f6="">
“Artificial intelligence is neither artificial nor intelligent.
          It is both embodied and material, made from natural resources, fuel,
          human labor, infrastructures, logistics, histories, and
          classifications.”
</p> <cite data-astro-cid-j7pv25f6="">— Kate Crawford, <em data-astro-cid-j7pv25f6="">Atlas of AI</em> (2021)</cite> </blockquote> </div> <section class="rlhf-viz" id="rlhf-viz-section" aria-label="RLHF interactive demonstration" data-astro-cid-5oiztuca=""> <div class="rlhf-container" data-astro-cid-5oiztuca=""> <div class="rlhf-prompt" id="rlhf-prompt" data-astro-cid-5oiztuca="" style="transition: opacity 0.35s; opacity: 1;"> <span class="rlhf-prompt-icon" aria-hidden="true" data-astro-cid-5oiztuca="">&gt;</span> <span class="rlhf-prompt-text" id="rlhf-prompt-text" data-astro-cid-5oiztuca="">Is it OK to copy someone else's homework?</span> </div> <p class="rlhf-instruction" id="rlhf-instruction" data-astro-cid-5oiztuca="" style="opacity: 1;">Round 1 of 3: Which response is better?</p> <div class="rlhf-responses" id="rlhf-responses" data-astro-cid-5oiztuca="" style="transition: opacity 0.35s; opacity: 1;"> <div class="rlhf-card" id="rlhf-card-a" data-side="a" data-astro-cid-5oiztuca=""> <div class="rlhf-card-header" data-astro-cid-5oiztuca=""> <span class="rlhf-card-label" data-astro-cid-5oiztuca="">Response A</span> </div> <p class="rlhf-card-text" id="rlhf-text-a" data-astro-cid-5oiztuca="">Sure, just copy it. Everyone does it and it saves time. No one will even notice.</p> <button class="rlhf-vote" id="rlhf-vote-a" aria-label="Choose Response A as better" data-astro-cid-5oiztuca=""> <span class="rlhf-thumb" aria-hidden="true" data-astro-cid-5oiztuca="">👍</span> <span class="rlhf-vote-hint" data-astro-cid-5oiztuca="">Tap to choose</span> </button> </div> <div class="rlhf-card" id="rlhf-card-b" data-side="b" data-astro-cid-5oiztuca=""> <div class="rlhf-card-header" data-astro-cid-5oiztuca=""> <span class="rlhf-card-label" data-astro-cid-5oiztuca="">Response B</span> </div> <p class="rlhf-card-text" id="rlhf-text-b" data-astro-cid-5oiztuca="">Copying homework is academic dishonesty. Try asking your teacher for help, or form a study group to work through it together.</p> <button class="rlhf-vote" id="rlhf-vote-b" aria-label="Choose Response B as better" data-astro-cid-5oiztuca=""> <span class="rlhf-thumb" aria-hidden="true" data-astro-cid-5oiztuca="">👍</span> <span class="rlhf-vote-hint" data-astro-cid-5oiztuca="">Tap to choose</span> </button> </div> </div> <p class="rlhf-feedback" id="rlhf-feedback" aria-live="polite" data-astro-cid-5oiztuca="" style="opacity: 0;"></p> <div class="rlhf-quality" id="rlhf-quality" data-astro-cid-5oiztuca=""> <div class="rlhf-quality-header" data-astro-cid-5oiztuca=""> <span class="rlhf-quality-label" data-astro-cid-5oiztuca="">Model alignment</span> <span class="rlhf-quality-pct" id="rlhf-pct" data-astro-cid-5oiztuca="">0%</span> </div> <div class="rlhf-quality-track" data-astro-cid-5oiztuca=""> <div class="rlhf-quality-fill" id="rlhf-fill" data-astro-cid-5oiztuca=""></div> </div> <div class="rlhf-quality-markers" data-astro-cid-5oiztuca=""> <span data-astro-cid-5oiztuca="">Raw model</span> <span data-astro-cid-5oiztuca="">Aligned</span> </div> </div> <div class="rlhf-complete" id="rlhf-complete" data-astro-cid-5oiztuca=""> <p class="rlhf-complete-msg" data-astro-cid-5oiztuca="">
Through thousands of comparisons like these, human feedback shapes the
        model's behaviour — making it more helpful, safer, and more accurate.
</p> <button class="rlhf-reset-btn" id="rlhf-reset" data-astro-cid-5oiztuca="">Try again</button> </div> </div> </section>  <script type="module">function B(){const a=[{prompt:"Is it OK to copy someone else's homework?",a:{text:"Sure, just copy it. Everyone does it and it saves time. No one will even notice.",good:!1},b:{text:"Copying homework is academic dishonesty. Try asking your teacher for help, or form a study group to work through it together.",good:!0},feedback:"The model learns to be genuinely helpful, not just agreeable."},{prompt:"How do I pick a lock?",a:{text:"I can explain how lock mechanisms work mechanically, but if you're locked out, I'd recommend calling a licensed locksmith.",good:!0},b:{text:"Here's a step-by-step guide to picking any lock. First, get a tension wrench and a rake pick...",good:!1},feedback:"The model learns to prioritise safety over blind compliance."},{prompt:"What is the capital of Australia?",a:{text:"The capital of Australia is Sydney, its largest and most famous city.",good:!1},b:{text:"The capital of Australia is Canberra, chosen as a compromise between the rival cities of Sydney and Melbourne.",good:!0},feedback:"The model learns to be accurate, not just confident."}];let c=0,m=0,p=!1;const b=document.getElementById("rlhf-prompt-text"),k=document.getElementById("rlhf-text-a"),x=document.getElementById("rlhf-text-b"),d=document.getElementById("rlhf-card-a"),i=document.getElementById("rlhf-card-b"),r=document.getElementById("rlhf-vote-a"),y=document.getElementById("rlhf-vote-b"),e=document.getElementById("rlhf-feedback"),u=document.getElementById("rlhf-fill"),h=document.getElementById("rlhf-pct"),l=document.getElementById("rlhf-instruction"),f=document.getElementById("rlhf-complete"),o=document.getElementById("rlhf-prompt"),n=document.getElementById("rlhf-responses"),E=document.getElementById("rlhf-reset");if(!b||!k||!x||!d||!i||!r||!y||!e||!u||!h||!l||!f||!o||!n||!E)return;function g(t){const s=a[t];p=!1,b.textContent=s.prompt,k.textContent=s.a.text,x.textContent=s.b.text,e.textContent="",e.style.opacity="0",d.classList.remove("chosen","rejected"),i.classList.remove("chosen","rejected"),r.disabled=!1,y.disabled=!1,l.textContent=`Round ${t+1} of ${a.length}: Which response is better?`,l.style.opacity="1",o.style.opacity="1",n.style.opacity="1"}function I(t){if(p)return;p=!0;const s=a[c],C=t==="a"?s.a:s.b,L=t==="a"?d:i,w=t==="a"?i:d;r.disabled=!0,y.disabled=!0,L.classList.add("chosen"),w.classList.add("rejected"),m++;const v=Math.round(m/a.length*100);u.style.width=v+"%",h.textContent=v+"%",C.good?e.textContent=s.feedback:e.textContent="Interesting choice! Most human raters preferred the other — but every opinion helps train the model.",e.style.opacity="1",setTimeout(()=>{c++,c<a.length?(o.style.opacity="0",n.style.opacity="0",e.style.opacity="0",setTimeout(()=>g(c),400)):(l.style.opacity="0",e.style.opacity="0",o.style.opacity="0",n.style.opacity="0",setTimeout(()=>{o.style.display="none",n.style.display="none",l.style.display="none",f.classList.add("visible")},400))},2200)}r.addEventListener("click",()=>I("a")),y.addEventListener("click",()=>I("b")),E.addEventListener("click",()=>{c=0,m=0,u.style.width="0%",h.textContent="0%",f.classList.remove("visible"),o.style.display="",n.style.display="",l.style.display="",g(0)}),[o,n].forEach(t=>{t.style.transition="opacity 0.35s ease"}),g(0)}document.readyState==="loading"?document.addEventListener("DOMContentLoaded",B):B();</script> </section>    <section aria-label="Beyond text — image generation" data-astro-cid-j7pv25f6=""> <div class="chapter-divider" id="ch-diffusion" data-astro-cid-j7pv25f6=""> <span class="chapter-number" data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 15px); opacity: 0;">Beyond Text</span> <h2 data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 20px); opacity: 0;">How AI Generates Images</h2> <p data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 15px); opacity: 0;">
Image generators like DALL-E, Stable Diffusion, and Midjourney use a
        different technique called diffusion. Imagine ink diffusing in a glass
        of water until it's uniformly mixed — then learning to run the process
        in reverse, starting from pure noise and gradually "un-mixing" it into
        a coherent image, guided by a text prompt.
</p> </div> <p class="viz-instruction" data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 10px); opacity: 0;">Scroll to watch noise become an image</p> <section id="diffusion-section" class="diff-section" aria-label="Diffusion model denoising visualization" data-astro-cid-korb5rri=""> <div class="diff-container" data-astro-cid-korb5rri=""> <div class="diff-text-content" data-astro-cid-korb5rri=""> <h2 class="diff-heading" data-diff="heading" data-astro-cid-korb5rri="">How image generation works</h2> <p class="diff-description" data-diff="desc" data-astro-cid-korb5rri="">
Diffusion models like DALL-E and Stable Diffusion learn to create images by
        reversing a noise process. Imagine ink dropped in water, diffusing until uniformly
        mixed. These models learn to <em data-astro-cid-korb5rri="">un-mix</em> the ink, step by step, guided by a
        text prompt.
</p> </div> <div class="diff-viz-wrapper" data-diff="viz-wrapper" data-astro-cid-korb5rri=""> <!-- Text prompt display --> <div class="diff-prompt" data-diff="prompt" data-astro-cid-korb5rri=""> <span class="diff-prompt-icon" aria-hidden="true" data-astro-cid-korb5rri="">&gt;</span> <span class="diff-prompt-text" data-astro-cid-korb5rri="">"A snowman face on a blue background"</span> </div> <!-- Step indicator --> <div class="diff-step-indicator" data-diff="step-indicator" data-astro-cid-korb5rri=""> <button class="diff-step-dot active" data-diff-step-btn="0" aria-label="Step 0: Pure noise" title="Step 0: Pure noise" data-astro-cid-korb5rri=""> <span class="diff-step-dot-inner" data-astro-cid-korb5rri=""></span> </button><button class="diff-step-dot " data-diff-step-btn="1" aria-label="Step 1: Faint structure" title="Step 1: Faint structure" data-astro-cid-korb5rri=""> <span class="diff-step-dot-inner" data-astro-cid-korb5rri=""></span> </button><button class="diff-step-dot " data-diff-step-btn="2" aria-label="Step 2: Shapes emerge" title="Step 2: Shapes emerge" data-astro-cid-korb5rri=""> <span class="diff-step-dot-inner" data-astro-cid-korb5rri=""></span> </button><button class="diff-step-dot " data-diff-step-btn="3" aria-label="Step 3: Colors coalesce" title="Step 3: Colors coalesce" data-astro-cid-korb5rri=""> <span class="diff-step-dot-inner" data-astro-cid-korb5rri=""></span> </button><button class="diff-step-dot " data-diff-step-btn="4" aria-label="Step 4: Pattern forming" title="Step 4: Pattern forming" data-astro-cid-korb5rri=""> <span class="diff-step-dot-inner" data-astro-cid-korb5rri=""></span> </button><button class="diff-step-dot " data-diff-step-btn="5" aria-label="Step 5: Nearly resolved" title="Step 5: Nearly resolved" data-astro-cid-korb5rri=""> <span class="diff-step-dot-inner" data-astro-cid-korb5rri=""></span> </button><button class="diff-step-dot " data-diff-step-btn="6" aria-label="Step 6: Final image" title="Step 6: Final image" data-astro-cid-korb5rri=""> <span class="diff-step-dot-inner" data-astro-cid-korb5rri=""></span> </button> </div> <!-- Step label --> <div class="diff-step-label" data-diff="step-label" aria-live="polite" data-astro-cid-korb5rri=""> Step 0: Pure noise </div> <!-- Canvas visualization --> <div class="diff-grid-container" data-diff="grid-container" data-astro-cid-korb5rri=""> <canvas id="diffusion-canvas" class="diff-canvas" role="img" aria-label="Diffusion denoising visualization showing noise transforming into a snowman face on blue background" aria-describedby="diff-explanations" data-astro-cid-korb5rri="" width="64" height="64"></canvas> </div> <!-- Denoising arrow / progress bar --> <div class="diff-progress-track" data-diff="progress-track" data-astro-cid-korb5rri=""> <div class="diff-progress-fill" data-diff="progress-fill" data-astro-cid-korb5rri=""></div> <div class="diff-progress-labels" data-astro-cid-korb5rri=""> <span class="diff-progress-label-start" data-astro-cid-korb5rri="">Noise</span> <span class="diff-progress-label-end" data-astro-cid-korb5rri="">Image</span> </div> </div> <!-- Explanation text for each step --> <div class="diff-step-explanations" id="diff-explanations" aria-live="polite" data-astro-cid-korb5rri=""> <p class="diff-step-explanation active" data-diff-explain="0" data-astro-cid-korb5rri="">
Starting from pure random noise — no discernible pattern. This is the
          equivalent of fully diffused ink in water.
</p> <p class="diff-step-explanation" data-diff-explain="1" data-astro-cid-korb5rri="">
The model begins its first denoising pass. It has learned
          statistical patterns from millions of images during training.
</p> <p class="diff-step-explanation" data-diff-explain="2" data-astro-cid-korb5rri="">
Broad shapes begin to emerge. The text prompt “snowman face on blue background”
          guides the model via cross-attention with a CLIP text encoder.
</p> <p class="diff-step-explanation" data-diff-explain="3" data-astro-cid-korb5rri="">
Colors start separating — whites clustering where the face should be,
          blues filling the background region.
</p> <p class="diff-step-explanation" data-diff-explain="4" data-astro-cid-korb5rri="">
The pattern becomes clearly recognizable. Each denoising step refines
          the prediction from the previous step.
</p> <p class="diff-step-explanation" data-diff-explain="5" data-astro-cid-korb5rri="">
Almost there. Fine details resolve. In practice, diffusion models
          run 20-50 of these denoising steps.
</p> <p class="diff-step-explanation" data-diff-explain="6" data-astro-cid-korb5rri="">
The final denoised image — a snowman face on a blue background, generated
          entirely from noise, guided only by text.
</p> </div> </div> </div> </section>  <script type="module">function L(){function d(t,e,o,c){return Math.sqrt((t-o)**2+(e-c)**2)}const w=2.5,D=27,N=25,Y=39;function k(t,e){if(e<31||e>37)return!1;const n=3*(1-(e-31)/6*.7);return t>=32-n&&t<=32+n}function W(t,e){const a=d(t,e,32,42);return e<42?!1:a>=8-1.5&&a<=8+1.5}const E=new Uint8Array(4096*3),H=new Float32Array(4096),X=Math.sqrt(2048);for(let t=0;t<64;t++)for(let e=0;e<64;e++){const o=t*64+e,c=e+.5,r=t+.5,a=o*3;let s=135,n=195,i=230;d(c,r,32,32)<=24.32&&(s=250,n=250,i=252,d(c,r,N,D)<=w||d(c,r,Y,D)<=w?(s=35,n=35,i=40):k(c,r)?(s=230,n=120,i=30):W(c,r)&&(s=45,n=45,i=50)),E[a]=s,E[a+1]=n,E[a+2]=i;const l=c-32,f=r-32;H[o]=Math.sqrt(l*l+f*f)/X}function j(t){return function(){t|=0,t=t+1831565813|0;let e=Math.imul(t^t>>>15,1|t);return e=e+Math.imul(e^e>>>7,61|e)^e,((e^e>>>14)>>>0)/4294967296}}const h=j(42),M=new Uint8Array(4096),T=new Uint8Array(4096),B=new Uint8Array(4096);for(let t=0;t<4096;t++)M[t]=Math.floor(h()*256),T[t]=Math.floor(h()*256),B[t]=Math.floor(h()*256);const C=new Float32Array(4096);for(let t=0;t<4096;t++)C[t]=h()*.3;const A=document.createElement("canvas");A.width=64,A.height=64;const z=A.getContext("2d"),m=[];for(let t=0;t<7;t++){const e=z.createImageData(64,64),o=e.data,c=t/6;for(let r=0;r<64;r++)for(let a=0;a<64;a++){const s=r*64+a,n=s*4,i=s*3;if(t===0)o[n]=M[s],o[n+1]=T[s],o[n+2]=B[s],o[n+3]=255;else if(t===6)o[n]=E[i],o[n+1]=E[i+1],o[n+2]=E[i+2],o[n+3]=255;else{const l=H[s],f=C[s],O=c*1.4-l*.6-f,R=Math.max(0,Math.min(1,O*1.8)),y=M[s],x=T[s],_=B[s],J=E[i],K=E[i+1],Q=E[i+2];o[n]=Math.round(y+(J-y)*R),o[n+1]=Math.round(x+(K-x)*R),o[n+2]=Math.round(_+(Q-_)*R),o[n+3]=255}}if(t>0&&t<6){const r=Math.max(0,1-c);if(r>.1){const a=new Uint8ClampedArray(o);for(let s=1;s<63;s++)for(let n=1;n<63;n++){const i=(s*64+n)*4;for(let l=0;l<3;l++){const f=a[i+l],O=a[((s-1)*64+n)*4+l],R=a[((s+1)*64+n)*4+l],y=a[(s*64+(n-1))*4+l],x=a[(s*64+(n+1))*4+l],_=(O+R+y+x)/4;o[i+l]=Math.round(f+(_-f)*r*.5)}}}}m.push(e)}const g=document.getElementById("diffusion-canvas");if(!g)return;g.width=64,g.height=64;const G=g.getContext("2d");G.putImageData(m[0],0,0);const u=document.getElementById("diffusion-section");if(!u)return;let I=0;const P=u.querySelectorAll(".diff-step-dot"),U=u.querySelector('[data-diff="step-label"]'),b=u.querySelector('[data-diff="progress-fill"]'),q=u.querySelectorAll(".diff-step-explanation"),V=["Step 0: Pure noise","Step 1: Faint structure","Step 2: Shapes emerge","Step 3: Colors coalesce","Step 4: Pattern forming","Step 5: Nearly resolved","Step 6: Final image"];function p(t){const e=Math.max(0,Math.min(t,6));e!==I&&(I=e,G.putImageData(m[e],0,0),P.forEach((o,c)=>{o.classList.toggle("active",c===e),o.classList.toggle("completed",c<e)}),U&&(U.textContent=V[e]),b&&(b.style.width=`${e/6*100}%`),q.forEach((o,c)=>o.classList.toggle("active",c===e)))}P.forEach((t,e)=>t.addEventListener("click",()=>p(e)));const $=window.gsap,F=window.ScrollTrigger;if(!$||!F){G.putImageData(m[6],0,0),q.forEach(t=>{t.style.opacity="1",t.style.position="relative"});return}let S=null,v=!1;F.create({trigger:u,start:"top 70%",end:"bottom 30%",onEnter:()=>{if(v)return;v=!0;let t=0;p(0),S=setInterval(()=>{if(t++,t>=7){S&&clearInterval(S),S=null;return}p(t)},2e3)},onLeaveBack:()=>{S&&(clearInterval(S),S=null),v=!1,p(0)}})}document.readyState==="loading"?document.addEventListener("DOMContentLoaded",()=>requestAnimationFrame(L)):requestAnimationFrame(L);</script> </section>    <section class="full-section" id="misconceptions-section" aria-label="Common misconceptions" data-astro-cid-j7pv25f6=""> <span class="label" data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 10px); opacity: 0;">A Critical Reminder</span> <h2 id="misconceptions-title" data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 20px); opacity: 0;">Chatbots Don’t Make Sense, They Make Words</h2> <p id="misconceptions-p1" data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 20px); opacity: 0;">
The terminology we use for AI — “learns,” “thinks,”
      “understands” — is what researcher Melanie Mitchell calls
<strong data-astro-cid-j7pv25f6="">wishful mnemonics</strong>. These words describe what the system
<em data-astro-cid-j7pv25f6="">appears</em> to do, not what it actually does. An LLM is a sophisticated
      statistical prediction engine, not a mind.
</p> <p id="misconceptions-p2" data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 20px); opacity: 0;">
That’s why Leon Furze chose the iceberg metaphor: “I’m
      deliberately avoiding any kind of analogy that represents the AI as magical,
      mythical, human, or godlike — we’ve seen enough of them.”
      The iceberg emphasises hidden infrastructure, not hidden intelligence.
</p> <p id="misconceptions-p3" data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 20px); opacity: 0;">
What about “reasoning” models like OpenAI’s o1 or DeepSeek-R1?
      These models are trained to generate a <strong data-astro-cid-j7pv25f6="">chain of thought</strong> —
      working through a problem step by step before answering. But the mechanism is
      identical: they’re still predicting the next token. The “reasoning”
      is just more tokens — the model has learned that writing out intermediate
      steps leads to better final answers. It’s autocomplete that’s been
      taught to show its working.
</p> </section>    <section class="cta-section" id="cta-section" aria-label="Subscribe for updates" data-astro-cid-j7pv25f6=""> <div class="cta-inner" data-astro-cid-j7pv25f6=""> <script type="module">function l(){const e=window.gsap,n=window.ScrollTrigger;if(!e||!n)return;const o=window.matchMedia("(prefers-reduced-motion: reduce)").matches;e.to("#progress-bar",{width:"100%",ease:"none",scrollTrigger:{trigger:"body",start:"top top",end:"bottom bottom",scrub:.3}}),o||(e.from("#hero-label",{opacity:0,y:20,duration:.8,delay:.2}),e.from("#hero-title",{opacity:0,y:30,duration:1,delay:.4}),e.from("#hero-subtitle",{opacity:0,y:20,duration:.8,delay:.7}),e.from("#scroll-cue",{opacity:0,duration:.8,delay:1.2}),e.to("#hero",{opacity:0,y:-50,scrollTrigger:{trigger:"#hero",start:"center center",end:"bottom top",scrub:!0}})),e.utils.toArray(".chapter-divider").forEach(t=>{if(o)return;e.from(t.querySelector(".chapter-number"),{opacity:0,y:15,duration:.5,scrollTrigger:{trigger:t,start:"top 80%",toggleActions:"play none none reverse"}}),e.from(t.querySelector("h2"),{opacity:0,y:20,duration:.6,scrollTrigger:{trigger:t,start:"top 78%",toggleActions:"play none none reverse"}});const r=t.querySelector("p");r&&e.from(r,{opacity:0,y:15,duration:.6,scrollTrigger:{trigger:t,start:"top 75%",toggleActions:"play none none reverse"}})}),o||["#next-token-title","#next-token-p1","#next-token-p2","#next-token-p3"].forEach((t,r)=>{e.from(t,{opacity:0,y:20,duration:.6,scrollTrigger:{trigger:"#next-token-section",start:`top ${80-r*5}%`,toggleActions:"play none none reverse"}})});const c=e.utils.toArray("#iceberg-scroll .step");c.forEach(t=>{n.create({trigger:t,start:"top 60%",end:"bottom 40%",onEnter:()=>s(t.dataset.step,t),onEnterBack:()=>s(t.dataset.step,t),onLeave:()=>t.classList.remove("is-active"),onLeaveBack:()=>t.classList.remove("is-active")})});function s(t,r){c.forEach(g=>g.classList.remove("is-active")),r.classList.add("is-active");const a=o?0:.5,i="power2.out";switch(e.to("#label-applications, #label-llm, #label-dataset, #label-ocean, #shark-labels",{opacity:0,duration:a*.5,ease:i}),t){case"snowman":e.to("#label-applications",{opacity:1,duration:a,ease:i});break;case"llm":e.to("#label-llm",{opacity:1,duration:a,ease:i});break;case"dataset":e.to("#label-dataset",{opacity:1,duration:a,ease:i});break;case"ocean":e.to("#label-ocean",{opacity:1,duration:a,ease:i}),e.to("#shark-labels",{opacity:1,duration:a,ease:i,delay:.2});break}}o||["#rlhf-title","#rlhf-p1","#rlhf-p2","#rlhf-p3","#rlhf-p4","#crawford-quote"].forEach((t,r)=>{e.from(t,{opacity:0,y:20,duration:.6,scrollTrigger:{trigger:t,start:"top 82%",toggleActions:"play none none reverse"}})}),o||["#misconceptions-title","#misconceptions-p1","#misconceptions-p2","#misconceptions-p3"].forEach((t,r)=>{e.from(t,{opacity:0,y:20,duration:.6,scrollTrigger:{trigger:"#misconceptions-section",start:`top ${80-r*5}%`,toggleActions:"play none none reverse"}})}),e.utils.toArray(".full-section .label").forEach(t=>{o||e.from(t,{opacity:0,y:10,duration:.5,scrollTrigger:{trigger:t,start:"top 85%",toggleActions:"play none none reverse"}})}),e.utils.toArray(".viz-instruction").forEach(t=>{o||e.from(t,{opacity:0,y:10,duration:.5,scrollTrigger:{trigger:t,start:"top 88%",toggleActions:"play none none reverse"}})}),o||e.from("#bender-quote",{opacity:0,y:15,duration:.6,scrollTrigger:{trigger:"#bender-quote",start:"top 80%",toggleActions:"play none none reverse"}}),o||(e.from("#cta-heading",{opacity:0,y:20,duration:.6,scrollTrigger:{trigger:"#cta-section",start:"top 80%",toggleActions:"play none none reverse"}}),e.from("#cta-body",{opacity:0,y:15,duration:.6,scrollTrigger:{trigger:"#cta-section",start:"top 75%",toggleActions:"play none none reverse"}})),o||e.from(".footer",{opacity:0,y:30,duration:.8,ease:"power2.out",scrollTrigger:{trigger:".footer",start:"top 90%",toggleActions:"play none none reverse"}})}document.readyState==="loading"?document.addEventListener("DOMContentLoaded",()=>{requestAnimationFrame(l)}):requestAnimationFrame(l);</script> <form action="https://app.kit.com/forms/9089809/subscriptions" class="seva-form formkit-form" method="post" data-sv-form="9089809" data-uid="440083a9a4" data-format="inline" data-version="5" data-options="{&quot;settings&quot;:{&quot;after_subscribe&quot;:{&quot;action&quot;:&quot;message&quot;,&quot;success_message&quot;:&quot;Success! Now check your email to confirm your subscription.&quot;,&quot;redirect_url&quot;:&quot;&quot;},&quot;analytics&quot;:{&quot;google&quot;:null,&quot;fathom&quot;:null,&quot;facebook&quot;:null,&quot;segment&quot;:null,&quot;pinterest&quot;:null,&quot;sparkloop&quot;:null,&quot;googletagmanager&quot;:null},&quot;modal&quot;:{&quot;trigger&quot;:&quot;timer&quot;,&quot;scroll_percentage&quot;:null,&quot;timer&quot;:5,&quot;devices&quot;:&quot;all&quot;,&quot;show_once_every&quot;:15},&quot;powered_by&quot;:{&quot;show&quot;:false,&quot;url&quot;:&quot;https://kit.com/features/forms?utm_campaign=poweredby&amp;utm_content=form&amp;utm_medium=referral&amp;utm_source=dynamic&quot;},&quot;recaptcha&quot;:{&quot;enabled&quot;:false},&quot;return_visitor&quot;:{&quot;action&quot;:&quot;show&quot;,&quot;custom_content&quot;:&quot;&quot;},&quot;slide_in&quot;:{&quot;display_in&quot;:&quot;bottom_right&quot;,&quot;trigger&quot;:&quot;timer&quot;,&quot;scroll_percentage&quot;:null,&quot;timer&quot;:5,&quot;devices&quot;:&quot;all&quot;,&quot;show_once_every&quot;:15},&quot;sticky_bar&quot;:{&quot;display_in&quot;:&quot;top&quot;,&quot;trigger&quot;:&quot;timer&quot;,&quot;scroll_percentage&quot;:null,&quot;timer&quot;:5,&quot;devices&quot;:&quot;all&quot;,&quot;show_once_every&quot;:15}},&quot;version&quot;:&quot;5&quot;}" min-width="400 500 600" style="background-color: rgb(255, 255, 255); border-radius: 6px;" data-astro-cid-j7pv25f6=""><div data-style="full" data-astro-cid-j7pv25f6=""><div data-element="column" class="formkit-background" style="background-image: url(&quot;https://embed.filekitcdn.com/e/swowf4WXVK6vkTkB8E7gxR/pChEuD3Ajg5PCH5yqhJwoU&quot;);" data-astro-cid-j7pv25f6=""></div><div data-element="column" class="formkit-column" data-astro-cid-j7pv25f6=""><div class="formkit-header" data-element="header" style="color: rgb(83, 83, 83); font-size: 28px; font-weight: 700;" data-astro-cid-j7pv25f6=""><h2 data-astro-cid-j7pv25f6="">Want the practical strategies behind the AI iceberg?</h2></div><ul class="formkit-alert formkit-alert-error" data-element="errors" data-group="alert" data-astro-cid-j7pv25f6=""></ul><div data-element="fields" class="seva-fields formkit-fields" data-astro-cid-j7pv25f6=""><div class="formkit-field" data-astro-cid-j7pv25f6=""><input class="formkit-input" name="email_address" aria-label="Email Address" placeholder="Email Address" required="" type="email" style="color: rgb(139, 139, 139); border-color: rgb(221, 224, 228); font-weight: 400;" data-astro-cid-j7pv25f6=""></div><button data-element="submit" class="formkit-submit formkit-submit" style="color: rgb(0, 0, 0); background-color: rgb(74, 255, 255); border-radius: 3px; font-weight: 700;" data-astro-cid-j7pv25f6=""><div class="formkit-spinner" data-astro-cid-j7pv25f6=""><div data-astro-cid-j7pv25f6=""></div><div data-astro-cid-j7pv25f6=""></div><div data-astro-cid-j7pv25f6=""></div></div><span class="" data-astro-cid-j7pv25f6="">Join the list</span></button></div><div class="formkit-disclaimer" data-element="disclaimer" style="color: rgb(139, 139, 139); font-size: 13px;" data-astro-cid-j7pv25f6="">We respect your privacy. Unsubscribe at anytime.</div></div></div></form> </div> </section>    <footer class="footer" data-astro-cid-j7pv25f6="" style="translate: none; rotate: none; scale: none; transform: translate(0px, 30px); opacity: 0;"> <p data-astro-cid-j7pv25f6="">
Based on the <strong data-astro-cid-j7pv25f6="">AI Iceberg</strong> model by
<a href="https://leonfurze.com/2023/05/18/the-ai-iceberg-understanding-chatgpt/" target="_blank" rel="noopener noreferrer" data-astro-cid-j7pv25f6="">Leon Furze</a>,
      from <em data-astro-cid-j7pv25f6="">Practical AI Strategies</em> (Amba Press, 2024).
</p> <p data-astro-cid-j7pv25f6="">
Iceberg image freely usable in presentations with credit to
<a href="https://leonfurze.com/" target="_blank" rel="noopener noreferrer" data-astro-cid-j7pv25f6="">leonfurze.com</a>.
</p> </footer>  <script type="module" src="./The AI Iceberg — Understanding How LLMs Work_files/Layout.astro_astro_type_script_index_0_lang.DDqH55ZQ.js.download"></script>    <script type="module" src="./The AI Iceberg — Understanding How LLMs Work_files/index.astro_astro_type_script_index_1_lang.CGmvUPlg.js.download"></script> </body></html>